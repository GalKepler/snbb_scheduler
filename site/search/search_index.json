{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"snbb-scheduler","text":"<p>A rule-based scheduler for the SNBB neuroimaging pipeline. Runs as a daily job: scans the filesystem, evaluates which processing steps are needed, and submits them to Slurm \u2014 automatically.</p> <pre><code>discover \u2192 evaluate \u2192 filter \u2192 submit \u2192 monitor\n</code></pre>"},{"location":"#what-it-does","title":"What it does","text":"<p><code>snbb-scheduler</code> watches a DICOM tree and a derivatives directory and continuously moves data through a pipeline of procedures:</p> <ol> <li>bids \u2014 converts DICOMs to BIDS format via heudiconv</li> <li>bids_post \u2014 derives DWI fieldmap EPI sidecars from the BIDS data</li> <li>defacing \u2014 defaces T1w images for data sharing</li> <li>qsiprep \u2014 DWI preprocessing via QSIPrep</li> <li>freesurfer \u2014 structural reconstruction via FreeSurfer recon-all</li> <li>qsirecon \u2014 tractography and connectivity via QSIRecon</li> </ol> <p>Each procedure declares what it depends on. The scheduler respects those dependencies automatically, so <code>qsiprep</code> is never submitted before <code>bids_post</code> completes.</p>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>sessions.py   \u2192   rules.py   \u2192   manifest.py   \u2192   submit.py\n(DataFrame)       (Rule fns)     (task table)       (sbatch)\n                                      \u2191\n                               audit.py / monitor.py\n</code></pre> Module Responsibility <code>sessions.py</code> Walk <code>dicom_root</code> (or read a CSV) \u2192 DataFrame of sessions <code>rules.py</code> Evaluate which procedures need to run for each session <code>manifest.py</code> Build the pending task table, filter in-flight jobs <code>submit.py</code> Construct and call <code>sbatch</code> for each task <code>monitor.py</code> Poll <code>sacct</code> to update job statuses <code>audit.py</code> Append structured JSONL events for every state change"},{"location":"#quick-start","title":"Quick start","text":"<pre><code># Install\ngit clone https://github.com/GalKepler/snbb_scheduler.git\ncd snbb_scheduler\npip install -e \".[dev]\"\n\n# See what would be submitted (no real jobs)\nsnbb-scheduler --config /etc/snbb/config.yaml run --dry-run\n\n# Submit real jobs\nsnbb-scheduler --config /etc/snbb/config.yaml run\n\n# Check the queue\nsnbb-scheduler --config /etc/snbb/config.yaml status\n\n# Show pending tasks\nsnbb-scheduler --config /etc/snbb/config.yaml manifest\n</code></pre>"},{"location":"#design-principles","title":"Design principles","text":"<ul> <li>Filesystem is the source of truth. No database. Completion is determined by looking at actual output files.</li> <li>Declarative rules. Adding a procedure requires only a YAML entry \u2014 no code changes.</li> <li>Conservative checks. If in doubt, mark incomplete and re-run.</li> <li>Safe by default. <code>--dry-run</code> is always available. The scheduler never deletes data.</li> <li>Idempotent. Running twice in a row submits nothing if in-flight jobs are tracked.</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or later</li> <li>Access to a Slurm cluster (for real job submission; <code>--dry-run</code> works without Slurm)</li> <li>The processing tools called by each script (Apptainer containers, FreeSurfer, etc.) must be available on the cluster</li> </ul>"},{"location":"installation/#install-from-source","title":"Install from source","text":"<pre><code>git clone https://github.com/GalKepler/snbb_scheduler.git\ncd snbb_scheduler\npip install -e \".[dev]\"\n</code></pre> <p>The <code>[dev]</code> extra installs pytest and coverage tools for running tests.</p>"},{"location":"installation/#install-docs-dependencies","title":"Install docs dependencies","text":"<p>If you want to build or serve this documentation locally:</p> <pre><code>pip install -e \".[docs]\"\nmkdocs serve          # live preview at http://127.0.0.1:8000\nmkdocs build --strict # build static site into site/\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify installation","text":"<pre><code>snbb-scheduler --help\n</code></pre> <p>Expected output: <pre><code>Usage: snbb-scheduler [OPTIONS] COMMAND [ARGS]...\n\n  snbb-scheduler: rule-based scheduler for the SNBB neuroimaging pipeline.\n\nOptions:\n  --config PATH        Path to YAML config file. Uses built-in defaults if omitted.\n  --slurm-mem MEM      Memory limit for Slurm jobs (e.g. 32G). Overrides config file.\n  --slurm-cpus N       CPUs per task for Slurm jobs. Overrides config file.\n  --slurm-log-dir DIR  Directory for Slurm stdout/stderr logs. Overrides config file.\n  --help               Show this message and exit.\n\nCommands:\n  manifest  Show the current task manifest without submitting.\n  monitor   Poll sacct for in-flight job statuses and update the state file.\n  retry     Remove failed state entries so they are retried on the next run.\n  run       Discover sessions, evaluate rules, and submit jobs to Slurm.\n  status    Show the current job state (pending/running/complete/failed).\n</code></pre></p>"},{"location":"installation/#run-the-tests","title":"Run the tests","text":"<pre><code>pytest\npytest --cov=snbb_scheduler   # with coverage report\n</code></pre>"},{"location":"api/","title":"Python API Overview","text":"<p>Use the <code>snbb_scheduler</code> modules directly when you need custom logic, scripting, or integration with other tools.</p>"},{"location":"api/#when-to-use-the-python-api","title":"When to use the Python API","text":"<ul> <li>Inspecting the manifest or state file in a notebook or script</li> <li>Building configs programmatically (multi-site setups)</li> <li>Adding procedures dynamically based on external logic</li> <li>Running the pipeline from within another Python process</li> <li>Writing custom reports or dashboards</li> </ul>"},{"location":"api/#module-map","title":"Module map","text":"Module Key exports Description <code>config</code> <code>SchedulerConfig</code>, <code>Procedure</code>, <code>DEFAULT_PROCEDURES</code> All path conventions and procedure declarations <code>sessions</code> <code>discover_sessions</code>, <code>load_sessions</code>, <code>sanitize_*</code> Session discovery from filesystem or CSV <code>checks</code> <code>is_complete</code> Completion checking for any procedure <code>rules</code> <code>build_rules</code>, <code>Rule</code> Rule evaluation logic <code>manifest</code> <code>build_manifest</code>, <code>load_state</code>, <code>save_state</code>, <code>filter_in_flight</code>, <code>reconcile_with_filesystem</code> Task manifest and state file management <code>submit</code> <code>submit_task</code>, <code>submit_manifest</code> sbatch command construction and submission <code>monitor</code> <code>poll_jobs</code>, <code>update_state_from_sacct</code> sacct polling and status updates <code>audit</code> <code>AuditLogger</code>, <code>get_logger</code> JSONL audit logging"},{"location":"api/#quick-examples","title":"Quick examples","text":""},{"location":"api/#inspect-the-pending-manifest","title":"Inspect the pending manifest","text":"<pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.sessions import discover_sessions\nfrom snbb_scheduler.manifest import build_manifest\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\nsessions = discover_sessions(cfg)\nmanifest = build_manifest(sessions, cfg)\n\nprint(manifest.groupby(\"procedure\").size())\n# procedure\n# bids          3\n# bids_post     2\n# qsiprep       1\n# dtype: int64\n</code></pre>"},{"location":"api/#run-the-full-pipeline","title":"Run the full pipeline","text":"<pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.manifest import build_manifest, filter_in_flight, load_state, save_state\nfrom snbb_scheduler.sessions import discover_sessions\nfrom snbb_scheduler.submit import submit_manifest\nimport pandas as pd\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\n\nsessions  = discover_sessions(cfg)\nmanifest  = build_manifest(sessions, cfg)\nstate     = load_state(cfg)\nmanifest  = filter_in_flight(manifest, state)\n\nnew_rows  = submit_manifest(manifest, cfg, dry_run=False)\n\nparts = [df for df in (state, new_rows) if not df.empty]\nif parts:\n    save_state(pd.concat(parts, ignore_index=True), cfg)\n</code></pre>"},{"location":"api/#check-completion-for-a-specific-session","title":"Check completion for a specific session","text":"<pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.checks import is_complete\n\ncfg  = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\nproc = cfg.get_procedure(\"freesurfer\")\npath = cfg.get_procedure_root(proc) / \"sub-0001\"\n\nprint(is_complete(proc, path, bids_root=cfg.bids_root, subject=\"sub-0001\"))\n</code></pre>"},{"location":"api/audit/","title":"<code>snbb_scheduler.audit</code>","text":"<p>JSONL audit logging for all scheduler events.</p> <pre><code>from snbb_scheduler.audit import AuditLogger, get_logger\n</code></pre>"},{"location":"api/audit/#get_loggerconfig","title":"<code>get_logger(config)</code>","text":"<p>Return an <code>AuditLogger</code> for the given config.</p> <pre><code>from snbb_scheduler.audit import get_logger\n\naudit = get_logger(cfg)\n</code></pre> <p>Uses <code>config.log_file</code> if set; otherwise defaults to <code>&lt;state_file_parent&gt;/scheduler_audit.jsonl</code>.</p>"},{"location":"api/audit/#auditlogger","title":"<code>AuditLogger</code>","text":"<p>Appends JSONL records to a log file. One record per event.</p> <pre><code>audit = AuditLogger(Path(\"/data/snbb/scheduler_audit.jsonl\"))\n</code></pre>"},{"location":"api/audit/#auditlogevent-subject-session-procedure-job_id-old_status-new_status-detail-extra","title":"<code>audit.log(event, *, subject, session, procedure, job_id, old_status, new_status, detail, **extra)</code>","text":"<p>Append a single JSONL record.</p> <p>Parameters:</p> Parameter Type Default Description <code>event</code> <code>str</code> \u2014 Event type (see table below) <code>subject</code> <code>str</code> <code>\"\"</code> BIDS subject label <code>session</code> <code>str</code> <code>\"\"</code> BIDS session label <code>procedure</code> <code>str</code> <code>\"\"</code> Procedure name <code>job_id</code> <code>str</code> or <code>None</code> <code>None</code> Slurm job ID (omitted if <code>None</code>) <code>old_status</code> <code>str</code> or <code>None</code> <code>None</code> Previous status (omitted if <code>None</code>) <code>new_status</code> <code>str</code> or <code>None</code> <code>None</code> New status (omitted if <code>None</code>) <code>detail</code> <code>str</code> <code>\"\"</code> Extra context string (omitted if empty) <code>**extra</code> \u2014 \u2014 Any additional key-value pairs to include in the record"},{"location":"api/audit/#event-types","title":"Event types","text":"Event When Key fields <code>submitted</code> Job submitted to Slurm <code>job_id</code> <code>status_change</code> sacct or filesystem updates a status <code>job_id</code>, <code>old_status</code>, <code>new_status</code> <code>error</code> sbatch exits non-zero <code>detail</code> (error message) <code>dry_run</code> <code>run --dry-run</code> <code>detail</code> (full sbatch command) <code>retry_cleared</code> <code>retry</code> removes a failed entry <code>job_id</code>, <code>old_status</code>"},{"location":"api/audit/#example","title":"Example","text":"<pre><code>from pathlib import Path\nfrom snbb_scheduler.audit import AuditLogger\n\naudit = AuditLogger(Path(\"/data/snbb/scheduler_audit.jsonl\"))\n\n# Log a submission\naudit.log(\n    \"submitted\",\n    subject=\"sub-0001\",\n    session=\"ses-202407110849\",\n    procedure=\"bids\",\n    job_id=\"12345\",\n)\n\n# Log a status change\naudit.log(\n    \"status_change\",\n    subject=\"sub-0001\",\n    session=\"ses-202407110849\",\n    procedure=\"bids\",\n    job_id=\"12345\",\n    old_status=\"pending\",\n    new_status=\"complete\",\n)\n</code></pre>"},{"location":"api/audit/#output-record","title":"Output record","text":"<pre><code>{\n  \"timestamp\": \"2024-11-01T06:00:12.345678+00:00\",\n  \"event\": \"submitted\",\n  \"subject\": \"sub-0001\",\n  \"session\": \"ses-202407110849\",\n  \"procedure\": \"bids\",\n  \"job_id\": \"12345\"\n}\n</code></pre>"},{"location":"api/audit/#notes","title":"Notes","text":"<ul> <li>The log file's parent directory is created automatically if it doesn't exist</li> <li>Records are appended (never overwritten) \u2014 the file grows indefinitely</li> <li>Set up log rotation if the scheduler runs daily (see Cron Setup)</li> <li>See Audit Log reference for querying and tailing the log</li> </ul>"},{"location":"api/checks/","title":"<code>snbb_scheduler.checks</code>","text":"<p>Completion checking for procedure outputs.</p> <pre><code>from snbb_scheduler.checks import is_complete\n</code></pre>"},{"location":"api/checks/#is_completeproc-output_path-kwargs","title":"<code>is_complete(proc, output_path, **kwargs)</code>","text":"<p>Return <code>True</code> if a procedure's output is considered complete.</p> <pre><code>from snbb_scheduler.checks import is_complete\nfrom pathlib import Path\n\nresult = is_complete(proc, output_path)\n</code></pre> <p>Parameters: - <code>proc</code> \u2014 <code>Procedure</code> instance - <code>output_path</code> \u2014 <code>Path</code> to the procedure's output directory for this subject/session - <code>**kwargs</code> \u2014 passed to specialized check functions (see below)</p> <p>Returns: <code>bool</code></p>"},{"location":"api/checks/#completion-logic","title":"Completion logic","text":"<code>proc.completion_marker</code> Completion criterion <code>None</code> Output directory exists and is non-empty <code>\"path/to/file\"</code> That specific file exists inside <code>output_path</code> <code>\"**/*.nii.gz\"</code> At least one file matching the glob exists <code>[\"pat1\", \"pat2\"]</code> ALL patterns match at least one file each <p>If <code>output_path</code> does not exist, always returns <code>False</code>.</p>"},{"location":"api/checks/#examples","title":"Examples","text":"<pre><code>from pathlib import Path\nfrom snbb_scheduler.config import Procedure\nfrom snbb_scheduler.checks import is_complete\n\n# Check a BIDS session (list marker)\nbids_proc = Procedure(\n    name=\"bids\", output_dir=\"\", script=\"snbb_run_bids.sh\",\n    completion_marker=[\"anat/*_T1w.nii.gz\", \"dwi/*_dwi.nii.gz\"]\n)\npath = Path(\"/data/snbb/bids/sub-0001/ses-202407110849\")\nprint(is_complete(bids_proc, path))  # True if both patterns match\n\n# Check freesurfer with session-count validation\nfs_proc = Procedure(\n    name=\"freesurfer\", output_dir=\"freesurfer\", script=\"snbb_run_freesurfer.sh\",\n    scope=\"subject\", completion_marker=\"scripts/recon-all.done\"\n)\npath = Path(\"/data/snbb/derivatives/freesurfer/sub-0001\")\nprint(is_complete(\n    fs_proc, path,\n    bids_root=Path(\"/data/snbb/bids\"),\n    subject=\"sub-0001\",\n))\n</code></pre>"},{"location":"api/checks/#specialized-checks","title":"Specialized checks","text":"<p>Three procedures use custom completion logic that goes beyond the marker pattern:</p>"},{"location":"api/checks/#freesurfer","title":"<code>freesurfer</code>","text":"<p><code>is_complete(proc, path, bids_root=..., subject=...)</code> checks: 1. <code>scripts/recon-all.done</code> must exist 2. The number of <code>-i</code> inputs recorded in <code>recon-all.done</code>'s <code>#CMDARGS</code> line must equal the number of T1w NIfTI files currently available in the BIDS dataset for that subject</p> <p>Without <code>bids_root</code> and <code>subject</code>, falls back to checking only for the marker file.</p>"},{"location":"api/checks/#qsiprep","title":"<code>qsiprep</code>","text":"<p><code>is_complete(proc, path, bids_root=..., subject=...)</code> checks: 1. At least one <code>ses-*</code> subdirectory exists in the QSIPrep subject output 2. The count of <code>ses-*</code> subdirectories equals the count of BIDS sessions with DWI data</p>"},{"location":"api/checks/#qsirecon","title":"<code>qsirecon</code>","text":"<p><code>is_complete(proc, path, derivatives_root=..., subject=...)</code> checks: 1. At least one <code>ses-*</code> subdirectory exists in the QSIRecon subject output 2. The count matches the number of <code>ses-*</code> subdirectories in the corresponding QSIPrep output</p>"},{"location":"api/checks/#registering-a-custom-specialized-check","title":"Registering a custom specialized check","text":"<p>If you add a procedure with complex completion logic, register a specialized check:</p> <pre><code>from snbb_scheduler.checks import _register_check\nfrom snbb_scheduler.config import Procedure\nfrom pathlib import Path\n\n@_register_check(\"myprocedure\")\ndef _check_myprocedure(proc: Procedure, output_path: Path, **kwargs) -&gt; bool:\n    # Custom logic here\n    return (output_path / \"DONE\").exists()\n</code></pre> <p>Note</p> <p><code>_register_check</code> is a private API. For most procedures, the standard <code>completion_marker</code> is sufficient.</p>"},{"location":"api/config/","title":"<code>snbb_scheduler.config</code>","text":"<p>Procedure declarations and scheduler configuration.</p> <pre><code>from snbb_scheduler.config import Procedure, SchedulerConfig, DEFAULT_PROCEDURES\n</code></pre>"},{"location":"api/config/#procedure","title":"<code>Procedure</code>","text":"<p>Declaration of a single processing procedure.</p> <pre><code>@dataclass\nclass Procedure:\n    name: str\n    output_dir: str\n    script: str\n    scope: Literal[\"session\", \"subject\"] = \"session\"\n    depends_on: list[str] = field(default_factory=list)\n    completion_marker: str | list[str] | None = None\n</code></pre>"},{"location":"api/config/#fields","title":"Fields","text":"Field Type Description <code>name</code> <code>str</code> Unique identifier used throughout the scheduler <code>output_dir</code> <code>str</code> Subdirectory under <code>derivatives_root</code>; <code>\"\"</code> means outputs go in <code>bids_root</code> <code>script</code> <code>str</code> Shell script filename passed to <code>sbatch</code> <code>scope</code> <code>\"session\"</code> or <code>\"subject\"</code> Whether one job runs per session or per subject <code>depends_on</code> <code>list[str]</code> Names of procedures that must complete first <code>completion_marker</code> <code>str</code>, <code>list[str]</code>, or <code>None</code> How to determine output is complete"},{"location":"api/config/#example","title":"Example","text":"<pre><code>from snbb_scheduler.config import Procedure\n\nmy_proc = Procedure(\n    name=\"fmriprep\",\n    output_dir=\"fmriprep\",\n    script=\"snbb_run_fmriprep.sh\",\n    scope=\"session\",\n    depends_on=[\"bids\"],\n    completion_marker=\"**/*.html\",\n)\n</code></pre>"},{"location":"api/config/#default_procedures","title":"<code>DEFAULT_PROCEDURES</code>","text":"<p>The built-in procedure list, in dependency order:</p> <pre><code>DEFAULT_PROCEDURES: list[Procedure] = [\n    # bids \u2192 bids_post \u2192 defacing\n    # bids_post \u2192 qsiprep (subject-scoped)\n    # bids_post \u2192 freesurfer (subject-scoped)\n    # qsiprep + freesurfer \u2192 qsirecon (subject-scoped)\n]\n</code></pre> <p>To add procedures without losing the defaults:</p> <pre><code>from snbb_scheduler.config import DEFAULT_PROCEDURES, Procedure, SchedulerConfig\n\nextra = Procedure(name=\"fmriprep\", ...)\ncfg = SchedulerConfig(\n    procedures=list(DEFAULT_PROCEDURES) + [extra],\n)\n</code></pre>"},{"location":"api/config/#schedulerconfig","title":"<code>SchedulerConfig</code>","text":"<p>All path conventions and settings in one dataclass.</p> <pre><code>@dataclass\nclass SchedulerConfig:\n    dicom_root: Path = Path(\"/data/snbb/dicom\")\n    bids_root: Path = Path(\"/data/snbb/bids\")\n    derivatives_root: Path = Path(\"/data/snbb/derivatives\")\n    slurm_partition: str = \"debug\"\n    slurm_account: str = \"snbb\"\n    slurm_mem: str | None = None\n    slurm_cpus_per_task: int | None = None\n    state_file: Path = Path(\"/data/snbb/.scheduler_state.parquet\")\n    slurm_log_dir: Path | None = None\n    log_file: Path | None = None\n    sessions_file: Path | None = None\n    procedures: list[Procedure] = field(default_factory=lambda: list(DEFAULT_PROCEDURES))\n</code></pre>"},{"location":"api/config/#schedulerconfigfrom_yamlpath","title":"<code>SchedulerConfig.from_yaml(path)</code>","text":"<p>Load config from a YAML file, overriding defaults.</p> <pre><code>cfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\n</code></pre> <p>Raises: - <code>FileNotFoundError</code> \u2014 if the path does not exist - <code>ValueError</code> \u2014 if the file contains invalid YAML - <code>ValueError</code> \u2014 if any <code>depends_on</code> references an unknown procedure name</p>"},{"location":"api/config/#schedulerconfigget_procedurename","title":"<code>SchedulerConfig.get_procedure(name)</code>","text":"<p>Look up a procedure by name.</p> <pre><code>proc = cfg.get_procedure(\"freesurfer\")\n# raises KeyError if not found\n</code></pre>"},{"location":"api/config/#schedulerconfigget_procedure_rootproc","title":"<code>SchedulerConfig.get_procedure_root(proc)</code>","text":"<p>Return the base output directory for a procedure.</p> <pre><code>root = cfg.get_procedure_root(proc)\n# proc.output_dir == \"\"  \u2192  returns cfg.bids_root\n# proc.output_dir != \"\"  \u2192  returns cfg.derivatives_root / proc.output_dir\n</code></pre>"},{"location":"api/config/#__post_init__-validation","title":"<code>__post_init__</code> validation","text":"<p>On construction, <code>SchedulerConfig</code> validates that every procedure's <code>depends_on</code> references a known procedure name. This prevents silent misconfiguration:</p> <pre><code># This raises ValueError at construction time:\nSchedulerConfig(procedures=[\n    Procedure(name=\"qsiprep\", depends_on=[\"typo_name\"], ...)\n])\n# ValueError: Procedure 'qsiprep' depends on 'typo_name', which is not in the procedures list.\n</code></pre>"},{"location":"api/manifest/","title":"<code>snbb_scheduler.manifest</code>","text":"<p>Task manifest and state file management.</p> <pre><code>from snbb_scheduler.manifest import (\n    build_manifest,\n    load_state,\n    save_state,\n    filter_in_flight,\n    reconcile_with_filesystem,\n)\n</code></pre>"},{"location":"api/manifest/#build_manifestsessions-config-forcefalse-force_proceduresnone","title":"<code>build_manifest(sessions, config, force=False, force_procedures=None)</code>","text":"<p>Evaluate rules against all sessions and return a task manifest.</p> <pre><code>manifest = build_manifest(sessions, cfg)\n</code></pre> <p>Parameters: - <code>sessions</code> \u2014 DataFrame from <code>discover_sessions</code> - <code>config</code> \u2014 <code>SchedulerConfig</code> instance - <code>force</code> \u2014 skip completion check for all (or selected) procedures - <code>force_procedures</code> \u2014 list of procedure names to force-requeue</p> <p>Returns: <code>pd.DataFrame</code> with columns <code>subject</code>, <code>session</code>, <code>procedure</code>, <code>dicom_path</code>, <code>priority</code></p> <p>The <code>priority</code> column reflects the position of the procedure in <code>config.procedures</code> (lower = submitted first).</p> <p>Subject-scoped procedures appear once per subject (deduplicated across sessions), with <code>session=\"\"</code>.</p>"},{"location":"api/manifest/#example","title":"Example","text":"<pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.sessions import discover_sessions\nfrom snbb_scheduler.manifest import build_manifest\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\nsessions = discover_sessions(cfg)\nmanifest = build_manifest(sessions, cfg)\n\nprint(manifest[[\"subject\", \"session\", \"procedure\", \"priority\"]])\n</code></pre>"},{"location":"api/manifest/#load_stateconfig","title":"<code>load_state(config)</code>","text":"<p>Load the state parquet file.</p> <pre><code>state = load_state(cfg)\n</code></pre> <p>Returns an empty DataFrame with the correct schema if the file does not exist (never raises <code>FileNotFoundError</code>).</p> <p>Schema: <code>subject</code>, <code>session</code>, <code>procedure</code>, <code>status</code>, <code>submitted_at</code>, <code>job_id</code></p>"},{"location":"api/manifest/#save_statestate-config","title":"<code>save_state(state, config)</code>","text":"<p>Persist the state DataFrame to the parquet state file.</p> <pre><code>save_state(state, cfg)\n</code></pre> <p>Creates parent directories if needed.</p>"},{"location":"api/manifest/#filter_in_flightmanifest-state","title":"<code>filter_in_flight(manifest, state)</code>","text":"<p>Remove tasks that are already <code>pending</code> or <code>running</code> in the state file.</p> <pre><code>filtered = filter_in_flight(manifest, state)\n</code></pre> <p>Compares on <code>(subject, session, procedure)</code>. Returns <code>manifest</code> unchanged if either DataFrame is empty.</p>"},{"location":"api/manifest/#example_1","title":"Example","text":"<pre><code>manifest = build_manifest(sessions, cfg)\nstate = load_state(cfg)\nmanifest = filter_in_flight(manifest, state)  # remove already-submitted tasks\n</code></pre>"},{"location":"api/manifest/#reconcile_with_filesystemstate-config-auditnone","title":"<code>reconcile_with_filesystem(state, config, audit=None)</code>","text":"<p>Mark pending/running tasks as <code>complete</code> when their output exists on disk.</p> <pre><code>updated = reconcile_with_filesystem(state, cfg)\n</code></pre> <p>Handles the case where sacct no longer tracks a completed job (job purged from retention, or sacct unavailable). For each in-flight task, runs <code>is_complete</code> against the actual output directory.</p> <p>Parameters: - <code>state</code> \u2014 current state DataFrame - <code>config</code> \u2014 <code>SchedulerConfig</code> instance - <code>audit</code> \u2014 optional <code>AuditLogger</code>; logs <code>status_change</code> events for each transition</p> <p>Returns: Modified copy of <code>state</code> with updated statuses. The original is unchanged.</p>"},{"location":"api/manifest/#example_2","title":"Example","text":"<pre><code>from snbb_scheduler.manifest import load_state, reconcile_with_filesystem, save_state\nfrom snbb_scheduler.audit import get_logger\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\naudit = get_logger(cfg)\nstate = load_state(cfg)\nupdated = reconcile_with_filesystem(state, cfg, audit=audit)\nif not updated.equals(state):\n    save_state(updated, cfg)\n</code></pre>"},{"location":"api/manifest/#full-pipeline-example","title":"Full pipeline example","text":"<pre><code>import pandas as pd\nfrom snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.sessions import discover_sessions\nfrom snbb_scheduler.manifest import (\n    build_manifest, filter_in_flight,\n    load_state, save_state, reconcile_with_filesystem,\n)\nfrom snbb_scheduler.monitor import update_state_from_sacct\nfrom snbb_scheduler.submit import submit_manifest\nfrom snbb_scheduler.audit import get_logger\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\naudit = get_logger(cfg)\n\n# Discover and evaluate\nsessions = discover_sessions(cfg)\nmanifest = build_manifest(sessions, cfg)\n\n# Update state from sacct + filesystem\nstate = load_state(cfg)\nstate = update_state_from_sacct(state, audit)\nstate = reconcile_with_filesystem(state, cfg, audit)\nsave_state(state, cfg)\n\n# Filter and submit\nmanifest = filter_in_flight(manifest, state)\nnew_rows = submit_manifest(manifest, cfg, dry_run=False, audit=audit)\n\n# Save combined state\nparts = [df for df in (state, new_rows) if not df.empty]\nif parts:\n    save_state(pd.concat(parts, ignore_index=True), cfg)\n</code></pre>"},{"location":"api/monitor/","title":"<code>snbb_scheduler.monitor</code>","text":"<p>sacct polling and job status updates.</p> <pre><code>from snbb_scheduler.monitor import poll_jobs, update_state_from_sacct\n</code></pre>"},{"location":"api/monitor/#poll_jobsjob_ids","title":"<code>poll_jobs(job_ids)</code>","text":"<p>Query <code>sacct</code> for the current state of each job ID.</p> <pre><code>states = poll_jobs([\"12345\", \"12346\", \"12347\"])\n# {\"12345\": \"complete\", \"12346\": \"running\", \"12347\": \"failed\"}\n</code></pre> <p>Parameters: - <code>job_ids</code> \u2014 list of Slurm job ID strings</p> <p>Returns: <code>dict[str, str]</code> mapping job_id \u2192 scheduler status string. Returns <code>{}</code> on error (sacct not found, non-zero exit, etc.).</p> <p>Slurm state mapping:</p> Slurm state Scheduler status <code>PENDING</code> <code>pending</code> <code>RUNNING</code> <code>running</code> <code>COMPLETED</code> <code>complete</code> <code>FAILED</code> <code>failed</code> <code>TIMEOUT</code> <code>failed</code> <code>CANCELLED</code> <code>failed</code> <code>OUT_OF_MEMORY</code> <code>failed</code> <code>NODE_FAIL</code> <code>failed</code> <p>Sub-step job IDs (containing <code>.</code>) are skipped. State suffixes like <code>\"CANCELLED by user\"</code> are normalized to the base state.</p>"},{"location":"api/monitor/#update_state_from_sacctstate-auditnone","title":"<code>update_state_from_sacct(state, audit=None)</code>","text":"<p>Poll sacct for in-flight jobs and update their statuses.</p> <pre><code>updated = update_state_from_sacct(state, audit=audit)\n</code></pre> <p>Parameters: - <code>state</code> \u2014 current scheduler state DataFrame - <code>audit</code> \u2014 optional <code>AuditLogger</code>; logs <code>status_change</code> events</p> <p>Returns: Modified copy of <code>state</code> with updated statuses. The original is unchanged.</p> <p>Only jobs with <code>status=pending</code> or <code>status=running</code> are queried. If sacct returns no results (unavailable or empty), the original state is returned unchanged.</p>"},{"location":"api/monitor/#example","title":"Example","text":"<pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.manifest import load_state, save_state\nfrom snbb_scheduler.monitor import update_state_from_sacct\nfrom snbb_scheduler.audit import get_logger\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\naudit = get_logger(cfg)\nstate = load_state(cfg)\n\nupdated = update_state_from_sacct(state, audit)\n\nif not updated.equals(state):\n    save_state(updated, cfg)\n    print(\"State updated from sacct.\")\n</code></pre>"},{"location":"api/monitor/#_slurm_state_map","title":"<code>_SLURM_STATE_MAP</code>","text":"<p>The mapping from Slurm state strings to scheduler status strings:</p> <pre><code>_SLURM_STATE_MAP = {\n    \"PENDING\": \"pending\",\n    \"RUNNING\": \"running\",\n    \"COMPLETED\": \"complete\",\n    \"FAILED\": \"failed\",\n    \"TIMEOUT\": \"failed\",\n    \"CANCELLED\": \"failed\",\n    \"OUT_OF_MEMORY\": \"failed\",\n    \"NODE_FAIL\": \"failed\",\n}\n</code></pre> <p>Unknown Slurm states are silently ignored (job status is not updated).</p>"},{"location":"api/monitor/#error-handling","title":"Error handling","text":"<ul> <li>If <code>sacct</code> is not found on <code>$PATH</code>, a warning is logged and <code>{}</code> is returned</li> <li>If <code>sacct</code> exits non-zero, a warning is logged and <code>{}</code> is returned</li> <li>Neither case raises an exception \u2014 the scheduler continues with unchanged statuses</li> <li>After sacct polling, <code>reconcile_with_filesystem</code> (in <code>manifest.py</code>) provides a second check based on actual output files</li> </ul>"},{"location":"api/rules/","title":"<code>snbb_scheduler.rules</code>","text":"<p>Rule evaluation logic \u2014 decides which procedures need to run for each session.</p> <pre><code>from snbb_scheduler.rules import build_rules, Rule\n</code></pre>"},{"location":"api/rules/#rule-type","title":"<code>Rule</code> type","text":"<pre><code>Rule = Callable[[pd.Series], bool]\n</code></pre> <p>A rule is a callable that accepts a session row (<code>pd.Series</code>) and returns <code>True</code> if the corresponding procedure needs to run for that session.</p>"},{"location":"api/rules/#build_rulesconfig-forcefalse-force_proceduresnone","title":"<code>build_rules(config, force=False, force_procedures=None)</code>","text":"<p>Generate a rule function for every procedure in <code>config</code>.</p> <pre><code>rules = build_rules(cfg)\n# rules == {\"bids\": &lt;fn&gt;, \"bids_post\": &lt;fn&gt;, \"qsiprep\": &lt;fn&gt;, ...}\n</code></pre> <p>Parameters: - <code>config</code> \u2014 <code>SchedulerConfig</code> instance - <code>force</code> \u2014 if <code>True</code>, skip the self-completion check (re-queue already-complete procedures) - <code>force_procedures</code> \u2014 if provided (list of names), only skip completion check for those procedures</p> <p>Returns: <code>dict[str, Rule]</code> mapping procedure name \u2192 rule callable</p>"},{"location":"api/rules/#each-rule-returns-true-when-all-hold","title":"Each rule returns <code>True</code> when all hold:","text":"<ol> <li><code>row[\"dicom_exists\"]</code> is <code>True</code></li> <li>All procedures in <code>proc.depends_on</code> are complete on disk</li> <li>This procedure's output is not yet complete (unless <code>--force</code> applies)</li> </ol>"},{"location":"api/rules/#example","title":"Example","text":"<pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.sessions import discover_sessions\nfrom snbb_scheduler.rules import build_rules\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\nsessions = discover_sessions(cfg)\nrules = build_rules(cfg)\n\n# Check which procedures need to run for the first session\nsession_row = sessions.iloc[0]\nfor name, rule in rules.items():\n    print(f\"{name}: {rule(session_row)}\")\n</code></pre>"},{"location":"api/rules/#force-mode","title":"Force mode","text":"<pre><code># Force all procedures\nrules = build_rules(cfg, force=True)\n\n# Force only qsiprep\nrules = build_rules(cfg, force=True, force_procedures=[\"qsiprep\"])\n</code></pre>"},{"location":"api/rules/#notes","title":"Notes","text":"<ul> <li>Rules are generated fresh on each <code>build_rules</code> call \u2014 they are lightweight closures</li> <li>Rules do not interact with the state file; they only check the filesystem</li> <li>The state file filtering (in-flight deduplication) happens separately in <code>manifest.filter_in_flight</code></li> <li><code>build_manifest</code> calls <code>build_rules</code> internally \u2014 you usually don't need to call it directly</li> </ul>"},{"location":"api/sessions/","title":"<code>snbb_scheduler.sessions</code>","text":"<p>Session discovery and sanitization.</p> <pre><code>from snbb_scheduler.sessions import discover_sessions, load_sessions\n</code></pre>"},{"location":"api/sessions/#discover_sessionsconfig","title":"<code>discover_sessions(config)</code>","text":"<p>Return a DataFrame of all sessions with path information.</p> <pre><code>sessions = discover_sessions(cfg)\n</code></pre> <p>Returns: <code>pd.DataFrame</code> with columns: - <code>subject</code> \u2014 BIDS subject label (e.g. <code>sub-0001</code>) - <code>session</code> \u2014 BIDS session label (e.g. <code>ses-202407110849</code>) - <code>dicom_path</code> \u2014 path to the DICOM directory (or <code>None</code>) - <code>dicom_exists</code> \u2014 <code>True</code> if the DICOM directory exists - <code>&lt;proc&gt;_path</code> \u2014 output path for each configured procedure - <code>&lt;proc&gt;_exists</code> \u2014 <code>True</code> if that procedure's output path exists</p> <p>Discovery modes: - Filesystem walk (default): scans <code>config.dicom_root</code> for <code>sub-*/ses-*/</code> directories - CSV mode: when <code>config.sessions_file</code> is set, reads the pre-built session list from that CSV</p>"},{"location":"api/sessions/#example","title":"Example","text":"<pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.sessions import discover_sessions\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\nsessions = discover_sessions(cfg)\n\nprint(sessions[[\"subject\", \"session\", \"bids_exists\", \"qsiprep_exists\"]])\n#      subject           session  bids_exists  qsiprep_exists\n#   sub-0001  ses-202407110849         True           False\n#   sub-0001  ses-202410100845         True            True\n#   sub-0002  ses-202407110849        False           False\n</code></pre>"},{"location":"api/sessions/#load_sessionscsv_path","title":"<code>load_sessions(csv_path)</code>","text":"<p>Load and sanitize a raw linked_sessions CSV file.</p> <pre><code>from snbb_scheduler.sessions import load_sessions\n\ndf = load_sessions(\"/data/snbb/linked_sessions.csv\")\n</code></pre> <p>Expected CSV columns: <code>SubjectCode</code>, <code>ScanID</code>, <code>dicom_path</code></p> <p>Returns: Deduplicated DataFrame with sanitized <code>subject_code</code>, <code>session_id</code>, and <code>dicom_path</code> columns.</p> <p>Raises: <code>ValueError</code> if required columns are missing.</p>"},{"location":"api/sessions/#sanitize_subject_codesubject_code","title":"<code>sanitize_subject_code(subject_code)</code>","text":"<p>Strip special characters and zero-pad to 4 digits.</p> <pre><code>sanitize_subject_code(\"CLMC-1\")   # \u2192 \"1\"  (strips -, then zfill(4) \u2192 \"0001\")\nsanitize_subject_code(42)         # \u2192 \"0042\"\nsanitize_subject_code(\"0001\")     # \u2192 \"0001\"\n</code></pre>"},{"location":"api/sessions/#sanitize_session_idsession_id","title":"<code>sanitize_session_id(session_id)</code>","text":"<p>Convert to string, strip special characters, and zero-pad to 12 digits.</p> <pre><code>sanitize_session_id(\"202407110849\")  # \u2192 \"202407110849\"\nsanitize_session_id(202407110849)    # \u2192 \"202407110849\"\nsanitize_session_id(\"2024-07-11\")    # \u2192 \"000020240711\"\n</code></pre>"},{"location":"api/sessions/#sessions-csv-format","title":"Sessions CSV format","text":"<p>When <code>config.sessions_file</code> is set, the CSV is read directly without a filesystem walk. The CSV must have been produced by <code>load_sessions</code> (which sanitizes <code>SubjectCode</code> \u2192 <code>subject_code</code>, <code>ScanID</code> \u2192 <code>session_id</code>) or match this format:</p> Column Description <code>SubjectCode</code> Raw subject code from the source database <code>ScanID</code> Raw scan/session ID <code>dicom_path</code> Absolute path to the DICOM directory, or blank/NaN if absent <p>The scheduler converts these to BIDS labels: <code>subject = f\"sub-{subject_code}\"</code>, <code>session = f\"ses-{session_id}\"</code>.</p>"},{"location":"api/submit/","title":"<code>snbb_scheduler.submit</code>","text":"<p>sbatch command construction and submission.</p> <pre><code>from snbb_scheduler.submit import submit_task, submit_manifest\n</code></pre>"},{"location":"api/submit/#submit_taskrow-config-dry_runfalse-auditnone","title":"<code>submit_task(row, config, dry_run=False, audit=None)</code>","text":"<p>Submit a single task to Slurm via <code>sbatch</code>.</p> <pre><code>job_id = submit_task(row, cfg, dry_run=False)\n</code></pre> <p>Parameters: - <code>row</code> \u2014 manifest row (<code>pd.Series</code>) with at least <code>procedure</code>, <code>subject</code>, <code>session</code> - <code>config</code> \u2014 <code>SchedulerConfig</code> instance supplying Slurm settings - <code>dry_run</code> \u2014 if <code>True</code>, print the command and return <code>None</code> without calling sbatch - <code>audit</code> \u2014 optional <code>AuditLogger</code>; logs <code>submitted</code>, <code>error</code>, or <code>dry_run</code> events</p> <p>Returns: Slurm job ID string on success, or <code>None</code> for dry runs.</p> <p>Raises: - <code>subprocess.CalledProcessError</code> \u2014 if sbatch exits non-zero - <code>RuntimeError</code> \u2014 if sbatch output doesn't match <code>\"Submitted batch job &lt;ID&gt;\"</code></p>"},{"location":"api/submit/#sbatch-command-construction","title":"sbatch command construction","text":"<p>The command is built from:</p> <pre><code>sbatch\n  [--partition=&lt;partition&gt;]        # omitted if config.slurm_partition is empty\n  --account=&lt;account&gt;\n  --job-name=&lt;job_name&gt;\n  [--mem=&lt;mem&gt;]                    # omitted if config.slurm_mem is None\n  [--cpus-per-task=&lt;cpus&gt;]         # omitted if config.slurm_cpus_per_task is None\n  [--output=&lt;log_dir&gt;/&lt;name&gt;_%j.out]  # added if config.slurm_log_dir is set\n  [--error=&lt;log_dir&gt;/&lt;name&gt;_%j.err]   # added if config.slurm_log_dir is set\n  &lt;script&gt;\n  &lt;subject&gt;\n  [&lt;session&gt; &lt;dicom_path&gt;]        # added for session-scoped procedures\n</code></pre>"},{"location":"api/submit/#job-naming","title":"Job naming","text":"Scope Job name <code>subject</code> <code>&lt;procedure&gt;_&lt;subject&gt;</code> <code>session</code> <code>&lt;procedure&gt;_&lt;subject&gt;_&lt;session&gt;</code>"},{"location":"api/submit/#example","title":"Example","text":"<pre><code>import pandas as pd\nfrom snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.submit import submit_task\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\n\nrow = pd.Series({\n    \"subject\": \"sub-0001\",\n    \"session\": \"ses-202407110849\",\n    \"procedure\": \"bids\",\n    \"dicom_path\": \"/data/snbb/dicom/sub-0001/ses-202407110849\",\n})\n\n# Dry run\nsubmit_task(row, cfg, dry_run=True)\n# [DRY RUN] Would submit: sbatch ...\n\n# Real submission\njob_id = submit_task(row, cfg, dry_run=False)\nprint(job_id)  # \"12345\"\n</code></pre>"},{"location":"api/submit/#submit_manifestmanifest-config-dry_runfalse-auditnone","title":"<code>submit_manifest(manifest, config, dry_run=False, audit=None)</code>","text":"<p>Submit all tasks in the manifest.</p> <pre><code>new_state = submit_manifest(manifest, cfg, dry_run=False, audit=audit)\n</code></pre> <p>Parameters: - <code>manifest</code> \u2014 DataFrame from <code>build_manifest</code> (after <code>filter_in_flight</code>) - <code>config</code> \u2014 <code>SchedulerConfig</code> instance - <code>dry_run</code> \u2014 if <code>True</code>, print commands without submitting - <code>audit</code> \u2014 optional <code>AuditLogger</code></p> <p>Returns: <code>pd.DataFrame</code> of new state rows with columns: <code>subject</code>, <code>session</code>, <code>procedure</code>, <code>status</code>, <code>submitted_at</code>, <code>job_id</code></p> <p>All new rows get <code>status=\"pending\"</code> and <code>submitted_at=now(UTC)</code>.</p> <p>Returns an empty DataFrame with the correct schema if <code>manifest</code> is empty.</p>"},{"location":"api/submit/#example_1","title":"Example","text":"<pre><code>new_rows = submit_manifest(manifest, cfg, dry_run=False, audit=audit)\nprint(f\"Submitted {len(new_rows)} jobs\")\n# Merge with existing state and save\nparts = [df for df in (state, new_rows) if not df.empty]\nif parts:\n    import pandas as pd\n    save_state(pd.concat(parts, ignore_index=True), cfg)\n</code></pre>"},{"location":"api/submit/#_build_job_namerow-proc_scope","title":"<code>_build_job_name(row, proc_scope)</code>","text":"<p>Internal helper that builds the Slurm job name string.</p> <pre><code>from snbb_scheduler.submit import _build_job_name\n\nname = _build_job_name(row, \"subject\")  # \"qsiprep_sub-0001\"\nname = _build_job_name(row, \"session\")  # \"bids_sub-0001_ses-202407110849\"\n</code></pre>"},{"location":"cli/","title":"CLI Overview","text":"<p><code>snbb-scheduler</code> is invoked as:</p> <pre><code>snbb-scheduler [GLOBAL OPTIONS] COMMAND [COMMAND OPTIONS]\n</code></pre>"},{"location":"cli/#global-options","title":"Global options","text":"<p>These options apply to all commands and are specified before the command name:</p> Option Description <code>--config PATH</code> Path to YAML config file. Uses built-in defaults if omitted. <code>--slurm-mem MEM</code> Memory limit for Slurm jobs (e.g. <code>32G</code>). Overrides config file. <code>--slurm-cpus N</code> CPUs per task for Slurm jobs. Overrides config file. <code>--slurm-log-dir DIR</code> Directory for Slurm stdout/stderr logs. Overrides config file."},{"location":"cli/#commands","title":"Commands","text":"Command Description <code>run</code> Discover sessions, evaluate rules, and submit jobs to Slurm <code>manifest</code> Show the pending task table without submitting <code>status</code> Show the full state file with current job statuses <code>monitor</code> Poll sacct and update job statuses in the state file <code>retry</code> Clear failed entries so they are re-submitted on the next run"},{"location":"cli/#examples","title":"Examples","text":"<pre><code># Dry run \u2014 see what would be submitted\nsnbb-scheduler --config /etc/snbb/config.yaml run --dry-run\n\n# Submit real jobs\nsnbb-scheduler --config /etc/snbb/config.yaml run\n\n# Submit with more memory than the config specifies\nsnbb-scheduler --config /etc/snbb/config.yaml --slurm-mem 64G run\n\n# Check job statuses\nsnbb-scheduler --config /etc/snbb/config.yaml status\n\n# Update statuses from sacct\nsnbb-scheduler --config /etc/snbb/config.yaml monitor\n\n# Retry all failed bids jobs for one subject\nsnbb-scheduler --config /etc/snbb/config.yaml retry --procedure bids --subject sub-0002\n</code></pre>"},{"location":"cli/manifest/","title":"<code>manifest</code>","text":"<p>Show the current task manifest without submitting anything. Useful for inspecting what <code>run</code> would submit.</p> <pre><code>snbb-scheduler --config CONFIG manifest\n</code></pre>"},{"location":"cli/manifest/#what-it-shows","title":"What it shows","text":"<p>The manifest is the list of tasks that need processing: procedures whose dependencies are met but whose own output is not yet complete. It does not apply the in-flight filter \u2014 it shows everything that would be submitted if you ran with <code>--force</code>.</p>"},{"location":"cli/manifest/#example-output","title":"Example output","text":"<pre><code>    subject                session   procedure  priority\n   sub-0001  ses-202407110849       bids              0\n   sub-0002  ses-202407110849       bids              0\n   sub-0003  ses-202407110849       bids_post         1\n   sub-0003  ses-202410100845       bids_post         1\n   sub-0003                         qsiprep           3\n   sub-0003                         freesurfer        4\n</code></pre>"},{"location":"cli/manifest/#columns","title":"Columns","text":"Column Description <code>subject</code> BIDS subject label <code>session</code> BIDS session label (empty for subject-scoped procedures) <code>procedure</code> Procedure name <code>priority</code> Submission order \u2014 lower = submitted first"},{"location":"cli/manifest/#notes","title":"Notes","text":"<ul> <li><code>priority</code> reflects the position of the procedure in <code>config.procedures</code> (lower index = lower priority value = submitted first)</li> <li>The manifest shows tasks that are not complete on the filesystem, regardless of the state file</li> <li>To see what <code>run</code> would actually submit (after filtering in-flight), use <code>run --dry-run</code></li> </ul>"},{"location":"cli/monitor/","title":"<code>monitor</code>","text":"<p>Poll <code>sacct</code> for in-flight job statuses and update the state file.</p> <pre><code>snbb-scheduler --config CONFIG monitor\n</code></pre>"},{"location":"cli/monitor/#what-it-does","title":"What it does","text":"<ol> <li>Loads the current state file</li> <li>Finds all jobs with <code>status=pending</code> or <code>status=running</code></li> <li>Queries <code>sacct</code> for their current Slurm states</li> <li>Maps Slurm states \u2192 scheduler statuses (see table below)</li> <li>Runs <code>reconcile_with_filesystem</code> \u2014 marks jobs as <code>complete</code> if their output exists on disk even if sacct no longer tracks them</li> <li>Saves the updated state file</li> <li>Prints a transition count and summary table</li> </ol>"},{"location":"cli/monitor/#example-output","title":"Example output","text":"<pre><code>Updated 3 job status(es).\n    procedure    status  count\n         bids  complete     12\n     bids_post  complete      8\n     bids_post   running      4\n      qsiprep    running      2\n   freesurfer    failed       1\n</code></pre>"},{"location":"cli/monitor/#slurm-state-mapping","title":"Slurm state mapping","text":"Slurm state Scheduler status <code>PENDING</code> <code>pending</code> <code>RUNNING</code> <code>running</code> <code>COMPLETED</code> <code>complete</code> <code>FAILED</code> <code>failed</code> <code>TIMEOUT</code> <code>failed</code> <code>CANCELLED</code> <code>failed</code> <code>OUT_OF_MEMORY</code> <code>failed</code> <code>NODE_FAIL</code> <code>failed</code>"},{"location":"cli/monitor/#automatic-monitoring","title":"Automatic monitoring","text":"<p><code>snbb-scheduler run</code> automatically runs the monitor step before submission (unless <code>--skip-monitor</code> is passed). Use the standalone <code>monitor</code> command to update statuses without triggering a new submission pass.</p>"},{"location":"cli/monitor/#when-sacct-is-unavailable","title":"When sacct is unavailable","text":"<p>If <code>sacct</code> is not found or returns an error, the command logs a warning and falls back to filesystem reconciliation only. No exception is raised \u2014 statuses remain as-is.</p>"},{"location":"cli/monitor/#notes","title":"Notes","text":"<ul> <li>Events are recorded to the audit log for every status transition</li> <li><code>monitor</code> is safe to run at any time \u2014 it never submits new jobs</li> <li>See Monitoring Jobs guide for recommended monitoring workflows</li> </ul>"},{"location":"cli/retry/","title":"<code>retry</code>","text":"<p>Remove failed state entries so they are re-submitted on the next <code>run</code>.</p> <pre><code>snbb-scheduler --config CONFIG retry [OPTIONS]\n</code></pre>"},{"location":"cli/retry/#options","title":"Options","text":"Option Description <code>--procedure NAME</code> Limit to failed entries for one procedure (e.g. <code>bids</code>) <code>--subject LABEL</code> Limit to failed entries for one subject (e.g. <code>sub-0002</code>) <p>Both filters can be combined. Without either filter, all failed entries are cleared.</p>"},{"location":"cli/retry/#what-it-does","title":"What it does","text":"<ol> <li>Loads the state file</li> <li>Finds rows where <code>status=failed</code>, optionally filtered by procedure and/or subject</li> <li>Removes those rows and saves the updated state file</li> <li>Logs a <code>retry_cleared</code> event to the audit log for each cleared entry</li> </ol> <p>On the next <code>snbb-scheduler run</code>, those sessions will be evaluated fresh and re-submitted if their dependencies are met.</p>"},{"location":"cli/retry/#examples","title":"Examples","text":"<pre><code># Retry all failed jobs\nsnbb-scheduler --config config.yaml retry\n\n# Retry only failed bids_post jobs\nsnbb-scheduler --config config.yaml retry --procedure bids_post\n\n# Retry only sub-0003\nsnbb-scheduler --config config.yaml retry --subject sub-0003\n\n# Retry bids for sub-0003 only\nsnbb-scheduler --config config.yaml retry --procedure bids --subject sub-0003\n</code></pre>"},{"location":"cli/retry/#example-output","title":"Example output","text":"<pre><code>Cleared 3 failed entry/entries. They will be retried on the next run.\n</code></pre>"},{"location":"cli/retry/#notes","title":"Notes","text":"<ul> <li><code>retry</code> only removes <code>failed</code> entries; <code>pending</code> and <code>running</code> entries are not affected</li> <li>After clearing, run <code>status</code> to confirm the entries are gone</li> <li>To also clear <code>pending</code> or <code>running</code> entries (e.g. after a cluster failure), edit the state file directly with pandas \u2014 see Forcing a Rerun</li> </ul>"},{"location":"cli/run/","title":"<code>run</code>","text":"<p>Discover sessions, evaluate rules, and submit pending jobs to Slurm.</p> <pre><code>snbb-scheduler --config CONFIG run [OPTIONS]\n</code></pre>"},{"location":"cli/run/#options","title":"Options","text":"Option Description <code>--dry-run</code> Print what would be submitted without actually calling sbatch <code>--force</code> Re-queue all procedures regardless of completion or in-flight status <code>--procedure NAME</code> Combined with <code>--force</code>: limit forced re-queuing to one procedure <code>--skip-monitor</code> Skip the automatic sacct status update that runs before submission"},{"location":"cli/run/#what-it-does","title":"What it does","text":"<ol> <li>Discover sessions from <code>dicom_root</code> (or <code>sessions_file</code>)</li> <li>Evaluate rules to find procedures that need to run</li> <li>Monitor (unless <code>--skip-monitor</code>): poll sacct + reconcile filesystem to update in-flight statuses</li> <li>Filter tasks that are already <code>pending</code> or <code>running</code></li> <li>Submit each remaining task via <code>sbatch</code></li> <li>Save the new state rows to the state file</li> </ol>"},{"location":"cli/run/#examples","title":"Examples","text":"<pre><code># Safe preview\nsnbb-scheduler --config config.yaml run --dry-run\n\n# Real run\nsnbb-scheduler --config config.yaml run\n\n# Force re-run of all qsiprep jobs (even if already complete)\nsnbb-scheduler --config config.yaml run --force --procedure qsiprep\n\n# Force re-run of everything\nsnbb-scheduler --config config.yaml run --force\n\n# Run without the pre-submission sacct poll\nsnbb-scheduler --config config.yaml run --skip-monitor\n</code></pre>"},{"location":"cli/run/#dry-run-output","title":"Dry-run output","text":"<pre><code>Discovering sessions\u2026\n  Found 47 session(s).\n  12 task(s) need processing.\n  10 task(s) after filtering in-flight jobs.\n[DRY RUN] Would submit: sbatch --partition=debug --account=snbb --job-name=qsiprep_sub-0031 snbb_run_qsiprep.sh sub-0031\n[DRY RUN] Would submit: sbatch --partition=debug --account=snbb --job-name=bids_sub-0044_ses-202411010600 snbb_run_bids.sh sub-0044 ses-202411010600 /data/snbb/dicom/sub-0044/ses-202411010600\n...\n[DRY RUN] Would submit 10 job(s).\n</code></pre>"},{"location":"cli/run/#real-run-output","title":"Real-run output","text":"<pre><code>Discovering sessions\u2026\n  Found 47 session(s).\n  12 task(s) need processing.\n  10 task(s) after filtering in-flight jobs.\nSubmitting: sbatch --partition=debug --account=snbb --job-name=qsiprep_sub-0031 snbb_run_qsiprep.sh sub-0031\nSubmitting: sbatch --partition=debug --account=snbb --job-name=bids_sub-0044_ses-202411010600 snbb_run_bids.sh sub-0044 ses-202411010600 /data/snbb/dicom/sub-0044/ses-202411010600\n...\nSubmitted 10 job(s). State saved to /data/snbb/.scheduler_state.parquet.\n</code></pre>"},{"location":"cli/run/#notes","title":"Notes","text":"<ul> <li>If <code>sbatch</code> is not available or exits non-zero, an exception is raised and the job is not recorded in the state file.</li> <li>The <code>--force</code> flag bypasses both the completion check and the in-flight filter. Use with care \u2014 it will submit duplicate jobs if the previous jobs are still running.</li> <li>See Forcing a Rerun for recommended force workflows.</li> </ul>"},{"location":"cli/status/","title":"<code>status</code>","text":"<p>Show the current job state \u2014 all submitted jobs and their statuses.</p> <pre><code>snbb-scheduler --config CONFIG status\n</code></pre>"},{"location":"cli/status/#what-it-shows","title":"What it shows","text":"<p>Reads the state file and prints:</p> <ol> <li>A summary table grouped by procedure and status with counts</li> <li>The full details table with one row per submitted job</li> </ol> <p>When <code>slurm_log_dir</code> is configured, a <code>log_path</code> column is added showing the expected <code>.out</code> log file path for each job.</p>"},{"location":"cli/status/#example-output","title":"Example output","text":"<pre><code>Summary:\n    procedure    status  count\n         bids  complete     12\n     bids_post  complete     10\n     bids_post   running      2\n      qsiprep  complete      8\n      qsiprep   pending      1\n   freesurfer  complete      7\n   freesurfer   running      1\n\n    subject                session   procedure    status           submitted_at  job_id\n   sub-0001  ses-202407110849        bids       complete  2024-11-01 06:00:00   10234\n   sub-0001  ses-202407110849        bids_post  complete  2024-11-01 06:00:00   10235\n   sub-0001                          qsiprep    complete  2024-11-02 06:00:00   10891\n   sub-0002  ses-202407110849        bids       complete  2024-11-01 06:00:00   10236\n   sub-0002  ses-202407110849        bids_post  running   2024-11-03 06:00:00   11042\n   sub-0003  ses-202410100845        bids       complete  2024-11-01 06:00:00   10237\n   sub-0003  ses-202410100845        bids_post   failed   2024-11-01 06:00:00   10238\n</code></pre>"},{"location":"cli/status/#with-log-paths","title":"With log paths","text":"<p>When <code>slurm_log_dir</code> is set in config, a <code>log_path</code> column appears:</p> <pre><code>   subject   procedure    status  job_id  log_path\n  sub-0001    qsiprep    running   10891  /data/snbb/logs/slurm/qsiprep/qsiprep_sub-0001_10891.out\n</code></pre>"},{"location":"cli/status/#notes","title":"Notes","text":"<ul> <li><code>status</code> reads the state file as-is \u2014 it does not poll Slurm. Use <code>monitor</code> to get fresh statuses from sacct.</li> <li>To clear failed entries, use <code>retry</code>.</li> <li>The state file can also be read directly with pandas: <code>pd.read_parquet(config.state_file)</code></li> </ul>"},{"location":"concepts/","title":"Concepts: Architecture &amp; Data Flow","text":""},{"location":"concepts/#the-pipeline","title":"The pipeline","text":"<p><code>snbb-scheduler</code> implements a linear data flow with five stages:</p> <pre><code>discover \u2192 evaluate \u2192 filter \u2192 submit \u2192 monitor\n</code></pre>"},{"location":"concepts/#1-discover","title":"1. Discover","text":"<p><code>sessions.py</code> scans the filesystem (or reads a CSV) and produces a sessions DataFrame \u2014 one row per <code>(subject, session)</code> pair. Each row contains:</p> <ul> <li><code>subject</code> / <code>session</code> \u2014 BIDS labels (<code>sub-0001</code>, <code>ses-202411010600</code>)</li> <li><code>dicom_path</code> / <code>dicom_exists</code> \u2014 location of raw DICOMs</li> <li><code>&lt;proc&gt;_path</code> / <code>&lt;proc&gt;_exists</code> \u2014 output path and existence flag for every configured procedure</li> </ul>"},{"location":"concepts/#2-evaluate","title":"2. Evaluate","text":"<p><code>rules.py</code> applies rule functions to each session row. A rule function for a procedure returns <code>True</code> if that procedure should run for that session. Rules check:</p> <ul> <li>whether the procedure's dependencies are already complete (<code>&lt;dep&gt;_exists</code> is True)</li> <li>whether the procedure's own output does not yet exist (unless <code>--force</code> is used)</li> </ul>"},{"location":"concepts/#3-filter","title":"3. Filter","text":"<p><code>manifest.py</code> builds the task table, then removes tasks that are already <code>pending</code> or <code>running</code> in the state file. This prevents duplicate submission when the scheduler runs twice.</p>"},{"location":"concepts/#4-submit","title":"4. Submit","text":"<p><code>submit.py</code> constructs the <code>sbatch</code> command for each task and runs it. On success, the task is recorded in the state file with <code>status=pending</code>.</p>"},{"location":"concepts/#5-monitor","title":"5. Monitor","text":"<p><code>monitor.py</code> polls <code>sacct</code> to update job statuses (<code>pending \u2192 running \u2192 complete/failed</code>). <code>manifest.py</code>'s <code>reconcile_with_filesystem</code> provides a secondary check: if a job is no longer tracked by sacct but its output exists on disk, it is marked <code>complete</code>.</p>"},{"location":"concepts/#module-map","title":"Module map","text":"<pre><code>src/snbb_scheduler/\n\u251c\u2500\u2500 config.py      # Procedure dataclass, DEFAULT_PROCEDURES, SchedulerConfig\n\u251c\u2500\u2500 sessions.py    # discover_sessions(), sanitize_subject_code/session_id, load_sessions\n\u251c\u2500\u2500 checks.py      # is_complete() + specialized checks for freesurfer, qsiprep, qsirecon\n\u251c\u2500\u2500 rules.py       # Rule type, build_rules()\n\u251c\u2500\u2500 manifest.py    # build_manifest(), load_state(), save_state(),\n\u2502                  # filter_in_flight(), reconcile_with_filesystem()\n\u251c\u2500\u2500 submit.py      # submit_task(), submit_manifest(), _build_job_name()\n\u251c\u2500\u2500 monitor.py     # poll_jobs(), update_state_from_sacct(), _SLURM_STATE_MAP\n\u251c\u2500\u2500 audit.py       # AuditLogger, get_logger()\n\u2514\u2500\u2500 cli.py         # Click CLI: run, manifest, status, monitor, retry\n</code></pre>"},{"location":"concepts/#key-design-constraints","title":"Key design constraints","text":"<p><code>config.py</code> is the only place paths are defined. All modules receive a <code>SchedulerConfig</code> instance; paths are never hardcoded elsewhere.</p> <p>Rules are declarative. Adding a new procedure requires only a YAML entry (or a <code>Procedure</code> dataclass). No code changes to <code>rules.py</code>, <code>manifest.py</code>, or <code>submit.py</code>.</p> <p>Filesystem is the source of truth. No database. All state is in a single Parquet file.</p> <p>FreeSurfer and QSIPrep are subject-scoped. Their output paths are <code>derivatives_root/&lt;name&gt;/sub-XXXX</code> \u2014 one directory per subject, not per session. All other procedures use <code>derivatives_root/&lt;name&gt;/sub-XXXX/ses-YY</code>. This asymmetry is tracked in the <code>scope</code> field of each <code>Procedure</code>.</p>"},{"location":"concepts/pipeline/","title":"The SNBB Pipeline","text":"<p>This page describes what each procedure actually does \u2014 the tools, the science, the inputs, and the outputs. All procedures run inside Apptainer containers (except <code>bids_post</code> and <code>defacing</code>, which are pure Python/FSL).</p>"},{"location":"concepts/pipeline/#pipeline-overview","title":"Pipeline overview","text":"<pre><code>DICOM\n  \u2514\u2500\u25b6 bids          DICOM \u2192 BIDS (heudiconv)\n        \u2514\u2500\u25b6 bids_post    Derive DWI fieldmap EPI, add IntendedFor\n              \u251c\u2500\u25b6 defacing       Deface T1w / T2w (FSL fsl_deface)\n              \u251c\u2500\u25b6 qsiprep        DWI preprocessing (QSIPrep)\n              \u2502     \u2514\u2500\u25b6 qsirecon  Tractography &amp; connectivity (QSIRecon / MRtrix3)\n              \u2514\u2500\u25b6 freesurfer     Cortical reconstruction (FreeSurfer recon-all)\n                    \u2514\u2500\u25b6 qsirecon  (same node, waits for both)\n</code></pre>"},{"location":"concepts/pipeline/#bids-dicom-to-bids-conversion","title":"<code>bids</code> \u2014 DICOM to BIDS conversion","text":"<p>Tool: heudiconv 1.3.4 via Apptainer BIDS spec: bids.neuroimaging.io Scope: session Slurm resources: 4 h, 8 GB RAM, 4 CPUs</p>"},{"location":"concepts/pipeline/#what-it-does","title":"What it does","text":"<p>Converts raw DICOM files for one session into BIDS format using heudiconv with a site-specific heuristic (<code>scripts/heuristic.py</code>). heudiconv reads DICOM metadata, applies the heuristic to decide which series goes where, runs <code>dcm2niix</code> for NIfTI conversion, and writes properly named files with JSON sidecars.</p>"},{"location":"concepts/pipeline/#expected-outputs-completion-markers","title":"Expected outputs (completion markers)","text":"<p>All of the following must be present in <code>bids_root/sub-XX/ses-YY/</code> for the session to be considered complete:</p> File pattern Modality <code>anat/*_T1w.nii.gz</code> Structural T1-weighted <code>dwi/*dir-AP*_dwi.nii.gz</code> / <code>.bvec</code> / <code>.bval</code> DWI \u2014 AP phase-encode direction <code>dwi/*dir-PA*_dwi.nii.gz</code> DWI \u2014 PA reverse phase-encode (6 directions, b=1000) <code>fmap/*acq-func_dir-AP*epi.nii.gz</code> Functional fieldmap \u2014 AP <code>fmap/*acq-func_dir-PA*epi.nii.gz</code> Functional fieldmap \u2014 PA <code>func/*task-rest_bold.nii.gz</code> Resting-state fMRI"},{"location":"concepts/pipeline/#bids_post-bids-fieldmap-post-processing","title":"<code>bids_post</code> \u2014 BIDS fieldmap post-processing","text":"<p>Tool: Custom Python script (<code>scripts/snbb_bids_post.py</code>) Scope: session Slurm resources: 30 min, 2 GB RAM, 1 CPU</p>"},{"location":"concepts/pipeline/#what-it-does_1","title":"What it does","text":"<p>heudiconv writes the short reverse phase-encode DWI acquisition as a DWI series in <code>dwi/</code>, but QSIPrep expects the corresponding fieldmap to live in <code>fmap/</code> as a proper EPI fieldmap. This script bridges that gap in three steps:</p> <p>Step 1 \u2014 Derive the DWI fieldmap EPI Reads each <code>dwi/*_dir-PA_dwi.nii.gz</code> and its companion <code>.bval</code>. Identifies b=0 volumes (bval &lt; 100 s/mm\u00b2) and computes their mean to produce a single 3-D b0 image. Writes the result to <code>fmap/*_acq-dwi_dir-PA_epi.nii.gz</code> with a JSON sidecar.</p> <p>Step 2 \u2014 Add <code>IntendedFor</code> fields Updates every <code>fmap/*_epi.json</code> to include a BIDS-compliant <code>IntendedFor</code> field: - <code>acq-dwi</code> fieldmaps \u2192 point to <code>dwi/*_dir-AP_dwi.nii.gz</code> (AP only) - <code>acq-func</code> fieldmaps \u2192 point to <code>func/*_bold.nii.gz</code></p> <p>Without <code>IntendedFor</code>, downstream tools like QSIPrep and fMRIPrep cannot determine which fieldmap applies to which scan.</p> <p>Step 3 \u2014 Hide spurious <code>.bvec</code>/<code>.bval</code> in <code>fmap/</code> Some heudiconv versions write <code>.bvec</code>/<code>.bval</code> alongside EPI fieldmaps. These confuse BIDS validators and downstream tools. The script renames them with a leading dot (e.g. <code>.filename.bvec</code>) to hide them without deleting them.</p>"},{"location":"concepts/pipeline/#completion-marker","title":"Completion marker","text":"<p><code>fmap/*acq-dwi*_epi.nii.gz</code> \u2014 the derived DWI fieldmap EPI file.</p>"},{"location":"concepts/pipeline/#defacing-t1w-t2w-defacing","title":"<code>defacing</code> \u2014 T1w / T2w defacing","text":"<p>Tool: FSL <code>fsl_deface</code> Scope: session Slurm resources: 1 h, 8 GB RAM, 4 CPUs</p>"},{"location":"concepts/pipeline/#what-it-does_2","title":"What it does","text":"<p>Applies <code>fsl_deface</code> to every T1w and T2w image in the session's <code>anat/</code> directory to remove facial features. The defaced images are written alongside the originals using the <code>acq-defaced</code> BIDS entity:</p> <pre><code>anat/sub-0001_ses-YY_T1w.nii.gz             \u2190 original (kept)\nanat/sub-0001_ses-YY_acq-defaced_T1w.nii.gz \u2190 defaced copy\n</code></pre> <p>JSON sidecars are copied alongside each defaced image. Only files without an existing <code>acq-</code> entity are processed, preventing double-defacing.</p> <p><code>fsl_deface</code> uses FSL BET brain extraction and nonlinear registration to a face template to mask out the facial region. The method is conservative \u2014 it errs on the side of removing too much rather than leaving facial features.</p>"},{"location":"concepts/pipeline/#why-defacing-matters","title":"Why defacing matters","text":"<p>Raw T1w images may allow facial re-identification. SNBB shares derivatives publicly; the defaced images are what get shared while the originals remain on-site.</p>"},{"location":"concepts/pipeline/#completion-marker_1","title":"Completion marker","text":"<p><code>anat/*acq-defaced*_T1w.nii.gz</code></p>"},{"location":"concepts/pipeline/#qsiprep-dwi-preprocessing","title":"<code>qsiprep</code> \u2014 DWI preprocessing","text":"<p>Tool: QSIPrep 1.1.1 via Apptainer Scope: subject (all sessions processed together in one job) Slurm resources: 12 h, 20 GB RAM, 8 CPUs</p>"},{"location":"concepts/pipeline/#what-it-does_3","title":"What it does","text":"<p>QSIPrep is a BIDS-App for preprocessing diffusion MRI data. For each subject it:</p> <ol> <li>Reads all DWI sessions from the BIDS dataset simultaneously, enabling across-session head motion correction</li> <li>Susceptibility distortion correction (SDC) using the <code>acq-dwi</code> EPI fieldmap produced by <code>bids_post</code> (Pepolar / TOPUP method: AP + PA b0 pair)</li> <li>Head motion correction \u2014 rigid-body registration of each DWI volume to a b0 template</li> <li>Eddy current correction \u2014 FSL eddy</li> <li>Co-registration \u2014 DWI \u2192 T1w space using ANTs</li> <li>Resampling to 1.6 mm isotropic voxels in T1w space (or MNI space for template maps)</li> <li>QC metrics \u2014 per-volume and per-series quality control TSV files (<code>*desc-image_qc.tsv</code>)</li> </ol> <p>The BIDS filter file (<code>examples/bids_filters.json</code>) can be used to restrict which runs QSIPrep processes.</p>"},{"location":"concepts/pipeline/#completion-markers","title":"Completion markers","text":"<p>All of the following must be present in <code>derivatives/qsiprep/sub-XX/</code> per session:</p> File pattern Description <code>ses-*/dwi/*dir-AP*_dwi_preproc.nii.gz</code> Preprocessed DWI (NIfTI) <code>ses-*/dwi/*dir-AP*_dwi_preproc.bvec</code> Rotated gradient vectors <code>ses-*/dwi/*dir-AP*_dwi_preproc.bval</code> b-values <code>ses-*/dwi/*dir-AP*desc-image_qc.tsv</code> QC metrics"},{"location":"concepts/pipeline/#local-scratch-mode","title":"Local-scratch mode","text":"<p>When <code>SNBB_LOCAL_TMP_ROOT</code> is set, BIDS input and QSIPrep output are staged on the compute node's local disk to reduce NFS I/O, then rsynced back on success.</p>"},{"location":"concepts/pipeline/#freesurfer-cortical-reconstruction","title":"<code>freesurfer</code> \u2014 Cortical reconstruction","text":"<p>Tool: FreeSurfer 8.1.0 via Apptainer Scope: subject Slurm resources: 24 h, 20 GB RAM, 8 CPUs</p>"},{"location":"concepts/pipeline/#what-it-does_4","title":"What it does","text":"<p>Runs FreeSurfer <code>recon-all</code> \u2014 the standard pipeline for cortical surface reconstruction from T1w (and optionally T2w) MRI. For each subject:</p> <ol> <li>Image selection \u2014 collects all T1w images across all sessions, excludes <code>acq-defaced</code> variants, and prefers <code>rec-norm</code> (normalized) variants when available. The same two-step filter applies to T2w.</li> <li>Multi-session input \u2014 all available T1w files are passed as separate <code>-i</code> inputs to <code>recon-all</code>, enabling within-subject averaging for improved SNR.</li> <li>T2w pial surface refinement \u2014 when T2w images are available, <code>recon-all -T2 ... -T2pial</code> is used to improve the accuracy of the pial surface, particularly at the GM/CSF boundary.</li> <li>Full <code>recon-all -all</code> \u2014 runs the complete FreeSurfer pipeline in parallel (<code>-openmp 8</code>): skull stripping, surface tessellation, cortical parcellation (Desikan-Killiany, Brodmann, etc.), subcortical segmentation, thickness and curvature maps.</li> </ol> <p>The FreeSurfer output is written to a temporary directory first, then rsynced to the final destination to handle read-only network filesystems.</p>"},{"location":"concepts/pipeline/#completion-check-specialized","title":"Completion check (specialized)","text":"<p>The standard marker <code>scripts/recon-all.done</code> is checked, plus the number of <code>-i</code> inputs recorded in the marker file's <code>#CMDARGS</code> line must equal the number of T1w images currently available in the BIDS dataset. This catches the case where new sessions were acquired after FreeSurfer ran \u2014 the subject is automatically re-queued to incorporate the new data.</p>"},{"location":"concepts/pipeline/#output","title":"Output","text":"<p>Standard FreeSurfer <code>SUBJECTS_DIR</code> layout under <code>derivatives/freesurfer/sub-XX/</code>: <pre><code>derivatives/freesurfer/sub-0001/\n\u251c\u2500\u2500 mri/           \u2190 volumes (T1.mgz, aparc+aseg.mgz, ...)\n\u251c\u2500\u2500 surf/          \u2190 surfaces (lh.white, rh.pial, ...)\n\u251c\u2500\u2500 label/         \u2190 parcellation labels\n\u251c\u2500\u2500 stats/         \u2190 cortical thickness, area, volume tables\n\u2514\u2500\u2500 scripts/\n    \u2514\u2500\u2500 recon-all.done   \u2190 completion marker\n</code></pre></p>"},{"location":"concepts/pipeline/#qsirecon-tractography-and-connectivity","title":"<code>qsirecon</code> \u2014 Tractography and connectivity","text":"<p>Tool: QSIRecon 1.2.0 via Apptainer Reconstruction spec: <code>scripts/qsirecon_full_spec.yaml</code> (<code>gal_multishell_scalars</code>) Scope: subject (depends on both <code>qsiprep</code> and <code>freesurfer</code>) Slurm resources: 12 h, 32 GB RAM, 8 CPUs</p>"},{"location":"concepts/pipeline/#what-it-does_5","title":"What it does","text":"<p>QSIRecon orchestrates a multi-step diffusion MRI reconstruction workflow defined in a YAML specification. The SNBB spec (<code>gal_multishell_scalars</code>) runs four stages:</p>"},{"location":"concepts/pipeline/#stage-1-diffusion-scalar-model-fitting","title":"Stage 1 \u2014 Diffusion scalar model fitting","text":"<p>Three complementary models are fit to the multi-shell data:</p> Model Software Scalars produced DKI \u2014 Diffusion Kurtosis Imaging DIPY MK, AK, RK, MKT, KFA (kurtosis); MD, AD, RD, FA (diffusion tensor) NODDI \u2014 Neurite Orientation Dispersion and Density Imaging AMICO NDI (neurite density), ODI (orientation dispersion), Viso (isotropic fraction) MAP-MRI \u2014 Mean Apparent Propagator MRI DIPY RTOP, RTAP, RTPP, NG, PA, MSD, QIV GQI \u2014 Generalized Q-sampling Imaging DSI Studio QA, GFA, ISO, NQA, RQA <p>NODDI parameters: <code>dIso=0.003</code>, <code>dPar=0.0017</code> (optimized for in-vivo brain at clinical field strengths).</p>"},{"location":"concepts/pipeline/#stage-2-mni-template-mapping","title":"Stage 2 \u2014 MNI template mapping","text":"<p>All scalar maps from Stage 1 are warped to MNI152NLin2009cAsym space using the T1w\u2192MNI warp from QSIPrep, enabling group-level analysis without additional registration.</p>"},{"location":"concepts/pipeline/#stage-3-msmt-csd-fibre-orientation-distribution","title":"Stage 3 \u2014 MSMT-CSD fibre orientation distribution","text":"<p>Multi-shell multi-tissue constrained spherical deconvolution (MSMT-CSD) (MRtrix3) is used to estimate white matter (WM), grey matter (GM), and CSF fibre orientation distributions (FODs) simultaneously from the multi-shell data.</p> <p>Response functions: pre-computed group-average response functions from 1,426 balanced subjects are used (<code>median_response_wm/gm/csf_balanced_1426.txt</code>) rather than per-subject estimation. This improves stability for subjects with pathological tissue.</p> <p>mtnormalize: multi-tissue log-domain intensity normalisation is applied after CSD to correct for global intensity differences.</p>"},{"location":"concepts/pipeline/#stage-4-tractography-with-anatomically-constrained-tractography-act","title":"Stage 4 \u2014 Tractography with anatomically constrained tractography (ACT)","text":"<p>Two complementary tractography algorithms are run using MRtrix3:</p> Algorithm Type Streamlines Details iFOD2 Probabilistic 1,000,000 2nd-order integration, backtracking, cropped at GM/WM interface SD_Stream Deterministic 1,000,000 Streamline deflection, cropped at GM/WM interface <p>Both use ACT (Anatomically Constrained Tractography) with a Hybrid Surface and Volume Segmentation (HSVS) 5-tissue-type (5TT) image derived from the FreeSurfer segmentation. ACT biologically constrains streamlines to begin and end in grey matter, dramatically reducing false-positive connections.</p> <p>SIFT2 (Smith et al., 2015) is applied to both tractograms to weight streamlines by a factor proportional to the FOD amplitude, correcting for biases introduced by tractography algorithm and FOD amplitude differences. SIFT2 weights are used in connectivity matrix construction.</p>"},{"location":"concepts/pipeline/#stage-5-connectivity-matrices","title":"Stage 5 \u2014 Connectivity matrices","text":"<p>Structural connectivity matrices are constructed for both iFOD2 and SD_Stream tractograms using <code>tck2connectome</code>. Four connectivity measures are computed for each:</p> Measure Description <code>sift_invnodevol_radius2_count</code> SIFT2-weighted streamline count, normalised by inverse node volume <code>radius2_count</code> Raw streamline count <code>sift_radius2_count</code> SIFT2-weighted streamline count <code>radius2_meanlength</code> Mean streamline length <p>Atlases are applied from <code>SNBB_ATLASES_DIR</code> (by default: <code>4S156Parcels</code> and <code>Schaefer2018N100n7Tian2020S1</code>).</p>"},{"location":"concepts/pipeline/#stage-6-pyafq-tractometry","title":"Stage 6 \u2014 pyAFQ tractometry","text":"<p>pyAFQ recognises ~24 major white matter bundles from the iFOD2 tractogram using atlas-based bundle recognition and extracts tissue property profiles sampled at 100 nodes along each bundle. This produces along-tract scalar maps (FA, MD, DKI metrics, etc.) for tract-specific microstructure analysis.</p>"},{"location":"concepts/pipeline/#completion-check-specialized_1","title":"Completion check (specialized)","text":"<p>The number of <code>ses-*</code> subdirectories in the QSIRecon output must match the number of <code>ses-*</code> directories in the corresponding QSIPrep subject output. This ensures re-queuing when new sessions are processed by QSIPrep.</p>"},{"location":"concepts/pipeline/#data-flow-summary","title":"Data flow summary","text":"<pre><code>DICOM\n  \u2502\n  \u25bc\nbids_root/sub-XX/ses-YY/\n  \u251c\u2500\u2500 anat/*_T1w.nii.gz\n  \u251c\u2500\u2500 dwi/*_dir-AP_dwi.{nii.gz,bvec,bval}\n  \u251c\u2500\u2500 dwi/*_dir-PA_dwi.nii.gz        \u2190 b0 volumes only\n  \u251c\u2500\u2500 fmap/*_acq-func_*.nii.gz        \u2190 written by heudiconv\n  \u251c\u2500\u2500 fmap/*_acq-dwi_dir-PA_epi.nii.gz  \u2190 derived by bids_post\n  \u251c\u2500\u2500 fmap/*_epi.json (IntendedFor)   \u2190 updated by bids_post\n  \u2514\u2500\u2500 func/*_bold.nii.gz\n  \u2502\n  \u25bc (defacing)\n  \u2514\u2500\u2500 anat/*_acq-defaced_T1w.nii.gz\n  \u2502\n  \u25bc (qsiprep)\nderivatives/qsiprep/sub-XX/ses-YY/dwi/\n  \u251c\u2500\u2500 *_dwi_preproc.{nii.gz,bvec,bval}\n  \u2514\u2500\u2500 *_desc-image_qc.tsv\n  \u2502\n  \u251c\u2500\u2500 \u25bc (freesurfer)\n  \u2502 derivatives/freesurfer/sub-XX/\n  \u2502   \u251c\u2500\u2500 mri/ surf/ label/ stats/\n  \u2502   \u2514\u2500\u2500 scripts/recon-all.done\n  \u2502\n  \u25bc (qsirecon \u2014 waits for both qsiprep + freesurfer)\nderivatives/qsirecon-MRtrix3_act-HSVS/sub-XX/ses-YY/dwi/\n  \u251c\u2500\u2500 *DIPYDKI*.nii.gz          \u2190 DKI scalars\n  \u251c\u2500\u2500 *AMICONODDI*.nii.gz       \u2190 NODDI scalars\n  \u251c\u2500\u2500 *DIPYMAPMRI*.nii.gz       \u2190 MAP-MRI scalars\n  \u251c\u2500\u2500 *DSIStudio*.nii.gz        \u2190 GQI scalars\n  \u251c\u2500\u2500 *MRtrix3_act-HSVS*.tck    \u2190 tractograms (iFOD2, SD_Stream)\n  \u251c\u2500\u2500 *MRtrix3_act-HSVS*_connectivity*.csv  \u2190 connectivity matrices\n  \u2514\u2500\u2500 *pyAFQ_TRACTOMETRY*/      \u2190 along-tract profiles\n</code></pre>"},{"location":"concepts/procedures/","title":"Procedures","text":"<p>A procedure is one step in the neuroimaging pipeline. It is declared as a <code>Procedure</code> dataclass instance and carries all the metadata the scheduler needs to decide when to run it and how to submit it.</p>"},{"location":"concepts/procedures/#the-procedure-dataclass","title":"The <code>Procedure</code> dataclass","text":"<pre><code>@dataclass\nclass Procedure:\n    name: str                                    # unique identifier, e.g. \"qsiprep\"\n    output_dir: str                              # subdirectory under derivatives_root\n    script: str                                  # sbatch script filename\n    scope: Literal[\"session\", \"subject\"] = \"session\"\n    depends_on: list[str] = field(default_factory=list)\n    completion_marker: str | list[str] | None = None\n</code></pre>"},{"location":"concepts/procedures/#fields","title":"Fields","text":"Field Type Description <code>name</code> <code>str</code> Unique identifier used in the state file, manifest, and CLI filters <code>output_dir</code> <code>str</code> Subdirectory under <code>derivatives_root</code>; empty string means outputs go in <code>bids_root</code> <code>script</code> <code>str</code> Shell script filename passed to <code>sbatch</code> <code>scope</code> <code>\"session\"</code> or <code>\"subject\"</code> Whether one job is run per session or one per subject <code>depends_on</code> <code>list[str]</code> Names of procedures that must be complete before this one runs <code>completion_marker</code> <code>str</code>, <code>list[str]</code>, or <code>None</code> How to decide the output is complete \u2014 see Completion Markers"},{"location":"concepts/procedures/#default-procedures","title":"Default procedures","text":"<p>The scheduler ships with six built-in procedures:</p> Name Scope Depends on Output <code>bids</code> session (nothing) <code>bids_root/sub-XX/ses-YY/</code> <code>bids_post</code> session <code>bids</code> <code>bids_root/sub-XX/ses-YY/fmap/</code> <code>defacing</code> session <code>bids_post</code> <code>bids_root/sub-XX/ses-YY/anat/*acq-defaced*</code> <code>qsiprep</code> subject <code>bids_post</code> <code>derivatives_root/qsiprep/sub-XX/</code> <code>freesurfer</code> subject <code>bids_post</code> <code>derivatives_root/freesurfer/sub-XX/</code> <code>qsirecon</code> subject <code>qsiprep</code>, <code>freesurfer</code> <code>derivatives_root/qsirecon-MRtrix3_act-HSVS/sub-XX/</code>"},{"location":"concepts/procedures/#dependency-graph","title":"Dependency graph","text":"<pre><code>bids\n \u2514\u2500\u2500 bids_post\n      \u251c\u2500\u2500 defacing\n      \u251c\u2500\u2500 qsiprep \u2500\u2500\u2510\n      \u2514\u2500\u2500 freesurfer\u2500\u2524\n                     \u2514\u2500\u2500 qsirecon\n</code></pre>"},{"location":"concepts/procedures/#subject-scope-vs-session-scope","title":"Subject scope vs. session scope","text":"<p>When a procedure has <code>scope: subject</code>, the scheduler:</p> <ul> <li>computes one output path per subject (<code>derivatives_root/&lt;name&gt;/sub-XXXX</code>)</li> <li>deduplicates: even if a subject has 3 sessions, only one job is submitted</li> <li>passes only <code>subject</code> as an argument to the script (not <code>session</code>)</li> </ul> <p>When <code>scope: session</code> (the default):</p> <ul> <li>each <code>(subject, session)</code> pair gets its own job</li> <li>the script receives <code>subject</code> and <code>session</code> as positional arguments</li> </ul>"},{"location":"concepts/procedures/#adding-a-procedure","title":"Adding a procedure","text":"<p>See the Adding a Procedure guide for step-by-step instructions.</p>"},{"location":"concepts/state-machine/","title":"State Machine","text":""},{"location":"concepts/state-machine/#status-lifecycle","title":"Status lifecycle","text":"<p>Every submitted job transitions through a defined set of statuses:</p> <pre><code>pending \u2192 running \u2192 complete\n               \u2198 failed\n</code></pre> Status Meaning <code>pending</code> Submitted to Slurm, not yet confirmed running <code>running</code> Slurm reports the job is active <code>complete</code> Output verified complete by the completion marker <code>failed</code> Slurm reported failure, or the job timed out / ran out of memory"},{"location":"concepts/state-machine/#how-transitions-happen","title":"How transitions happen","text":"<ol> <li><code>pending</code> \u2014 set immediately when <code>sbatch</code> returns a job ID</li> <li><code>running</code> / <code>complete</code> / <code>failed</code> \u2014 updated by <code>snbb-scheduler monitor</code> (or automatically at the start of <code>snbb-scheduler run</code>)</li> <li><code>complete</code> (filesystem path) \u2014 <code>reconcile_with_filesystem</code> catches jobs that sacct no longer tracks but whose outputs exist on disk</li> <li>Clearing <code>failed</code> \u2014 <code>snbb-scheduler retry</code> removes failed entries so they are re-submitted on the next <code>run</code></li> </ol>"},{"location":"concepts/state-machine/#the-state-file","title":"The state file","text":"<p>The scheduler tracks every submitted job in a single Apache Parquet file configured via <code>state_file</code> in <code>config.yaml</code>. No external database is required.</p>"},{"location":"concepts/state-machine/#schema","title":"Schema","text":"Column Type Description <code>subject</code> string BIDS subject label, e.g. <code>sub-0001</code> <code>session</code> string BIDS session label, e.g. <code>ses-202411010600</code>; empty string for subject-scoped procedures <code>procedure</code> string Procedure name, e.g. <code>bids</code>, <code>qsiprep</code> <code>status</code> string One of <code>pending</code>, <code>running</code>, <code>complete</code>, <code>failed</code> <code>submitted_at</code> datetime (UTC) Timestamp of initial submission <code>job_id</code> string Slurm job ID returned by <code>sbatch</code>"},{"location":"concepts/state-machine/#in-flight-deduplication","title":"In-flight deduplication","text":"<p>Before submission, <code>filter_in_flight</code> removes from the manifest any task that already has <code>status=pending</code> or <code>status=running</code> in the state file. This prevents a second submission of the same job when the scheduler runs twice in quick succession.</p>"},{"location":"concepts/state-machine/#reading-the-state-file-directly","title":"Reading the state file directly","text":"<pre><code>import pandas as pd\n\nstate = pd.read_parquet(\"/data/snbb/.scheduler_state.parquet\")\n\n# Show all failed jobs\nprint(state[state[\"status\"] == \"failed\"])\n\n# Count by procedure and status\nprint(state.groupby([\"procedure\", \"status\"]).size())\n</code></pre>"},{"location":"concepts/state-machine/#state-file-location","title":"State file location","text":"<p>Set <code>state_file</code> in <code>config.yaml</code>:</p> <pre><code>state_file: /data/snbb/.scheduler_state.parquet\n</code></pre> <p>If the file does not exist on first run, it is created automatically.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>All site-specific paths and settings live in a single YAML file. The scheduler has built-in defaults; override only what differs on your system.</p>"},{"location":"configuration/#loading-config","title":"Loading config","text":"<p>Pass the config path to every CLI command:</p> <pre><code>snbb-scheduler --config /etc/snbb/config.yaml run\n</code></pre> <p>Or load it in Python:</p> <pre><code>from snbb_scheduler.config import SchedulerConfig\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\n</code></pre>"},{"location":"configuration/#minimal-config","title":"Minimal config","text":"<pre><code># /etc/snbb/config.yaml\ndicom_root:       /data/snbb/dicom\nbids_root:        /data/snbb/bids\nderivatives_root: /data/snbb/derivatives\nstate_file:       /data/snbb/.scheduler_state.parquet\n\nslurm_partition: debug\nslurm_account:   snbb\n</code></pre> <p>With no <code>procedures</code> key the built-in defaults run: bids \u2192 bids_post \u2192 defacing, bids_post \u2192 qsiprep, bids_post \u2192 freesurfer, qsiprep + freesurfer \u2192 qsirecon.</p>"},{"location":"configuration/#full-config-reference","title":"Full config reference","text":"<pre><code># \u2500\u2500 Paths \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndicom_root:       /data/snbb/dicom         # raw DICOM tree: sub-*/ses-*/\nbids_root:        /data/snbb/bids          # BIDS dataset root\nderivatives_root: /data/snbb/derivatives   # all derivatives\n\n# \u2500\u2500 State tracking \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nstate_file: /data/snbb/.scheduler_state.parquet\n# Optional: defaults to &lt;state_file_parent&gt;/scheduler_audit.jsonl\nlog_file:   /data/snbb/scheduler_audit.jsonl\n\n# \u2500\u2500 Session discovery (optional) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# When set, filesystem walk is skipped and sessions are read from this CSV.\n# CSV must have columns: SubjectCode, ScanID, dicom_path\nsessions_file: /data/snbb/linked_sessions.csv\n\n# \u2500\u2500 Slurm settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nslurm_partition: debug    # omit or \"\" for clusters without partitions\nslurm_account:   snbb\nslurm_mem:       32G      # optional: adds --mem=32G to sbatch\nslurm_cpus_per_task: 8    # optional: adds --cpus-per-task=8 to sbatch\n\n# Slurm log directory \u2014 adds --output and --error to sbatch.\n# Subdirectories are created per procedure: &lt;slurm_log_dir&gt;/&lt;procedure&gt;/\nslurm_log_dir: /data/snbb/logs/slurm\n\n# \u2500\u2500 Procedures \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Omit this section to use the built-in defaults.\nprocedures:\n  - name: bids\n    output_dir: \"\"          # empty string \u2192 outputs go in bids_root\n    script: snbb_run_bids.sh\n    scope: session\n    depends_on: []\n    completion_marker:\n      - \"anat/*_T1w.nii.gz\"\n      - \"dwi/*dir-AP*_dwi.nii.gz\"\n      - \"dwi/*dir-AP*_dwi.bvec\"\n      - \"dwi/*dir-AP*_dwi.bval\"\n      - \"dwi/*dir-PA*_dwi.nii.gz\"\n      - \"fmap/*acq-func_dir-AP*epi.nii.gz\"\n      - \"fmap/*acq-func_dir-PA*epi.nii.gz\"\n      - \"func/*task-rest_bold.nii.gz\"\n\n  - name: bids_post\n    output_dir: \"\"\n    script: snbb_run_bids_post.sh\n    scope: session\n    depends_on: [bids]\n    completion_marker: \"fmap/*acq-dwi*_epi.nii.gz\"\n\n  - name: defacing\n    output_dir: \"\"\n    script: snbb_run_defacing.sh\n    scope: session\n    depends_on: [bids_post]\n    completion_marker: \"anat/*acq-defaced*_T1w.nii.gz\"\n\n  - name: qsiprep\n    output_dir: qsiprep\n    script: snbb_run_qsiprep.sh\n    scope: subject\n    depends_on: [bids_post]\n    completion_marker:\n      - \"ses-*/dwi/*dir-AP*_dwi_preproc.nii.gz\"\n      - \"ses-*/dwi/*dir-AP*_dwi_preproc.bvec\"\n      - \"ses-*/dwi/*dir-AP*_dwi_preproc.bval\"\n      - \"ses-*/dwi/*dir-AP*desc-image_qc.tsv\"\n\n  - name: freesurfer\n    output_dir: freesurfer\n    script: snbb_run_freesurfer.sh\n    scope: subject\n    depends_on: [bids_post]\n    completion_marker: \"scripts/recon-all.done\"\n\n  - name: qsirecon\n    output_dir: qsirecon-MRtrix3_act-HSVS\n    script: snbb_run_qsirecon.sh\n    scope: subject\n    depends_on: [qsiprep, freesurfer]\n    completion_marker: null\n</code></pre>"},{"location":"configuration/#field-reference","title":"Field reference","text":"Field Type Default Description <code>dicom_root</code> path <code>/data/snbb/dicom</code> Root of the raw DICOM tree <code>bids_root</code> path <code>/data/snbb/bids</code> BIDS dataset root <code>derivatives_root</code> path <code>/data/snbb/derivatives</code> Root for all derivative outputs <code>state_file</code> path <code>/data/snbb/.scheduler_state.parquet</code> Parquet state file <code>log_file</code> path (auto) JSONL audit log; defaults next to <code>state_file</code> <code>sessions_file</code> path <code>null</code> Optional pre-built session CSV <code>slurm_partition</code> str <code>\"debug\"</code> Slurm partition; omit <code>--partition</code> if empty <code>slurm_account</code> str <code>\"snbb\"</code> Slurm account for <code>--account</code> <code>slurm_mem</code> str <code>null</code> Memory per job, e.g. <code>\"32G\"</code> <code>slurm_cpus_per_task</code> int <code>null</code> CPUs per task <code>slurm_log_dir</code> path <code>null</code> Directory for <code>--output</code>/<code>--error</code> log files <code>procedures</code> list (built-in defaults) List of procedure declarations"},{"location":"configuration/#overriding-settings-from-the-cli","title":"Overriding settings from the CLI","text":"<p>Some fields can be overridden per-invocation without editing the config file:</p> <pre><code>snbb-scheduler --config config.yaml --slurm-mem 64G --slurm-cpus 16 run\nsnbb-scheduler --config config.yaml --slurm-log-dir /tmp/logs run --dry-run\n</code></pre> <p>See CLI Overview for the full list of global options.</p>"},{"location":"configuration/completion-markers/","title":"Completion Markers","text":"<p>The <code>completion_marker</code> field on a <code>Procedure</code> controls how the scheduler decides whether a procedure's output is already complete. Conservative checks mean a procedure is re-run if the output looks incomplete.</p>"},{"location":"configuration/completion-markers/#types-of-markers","title":"Types of markers","text":""},{"location":"configuration/completion-markers/#null-directory-must-be-non-empty","title":"<code>null</code> \u2014 directory must be non-empty","text":"<pre><code>completion_marker: null\n</code></pre> <p>The output directory must exist and contain at least one file or subdirectory.</p> <p>Used by: <code>qsirecon</code></p>"},{"location":"configuration/completion-markers/#single-glob-pattern","title":"Single glob pattern","text":"<pre><code>completion_marker: \"**/*.nii.gz\"\n</code></pre> <p>At least one file matching the glob must exist inside the output directory (using <code>Path.glob</code>).</p> <p>Examples:</p> <pre><code>completion_marker: \"fmap/*acq-dwi*_epi.nii.gz\"   # bids_post: derived fieldmap written\ncompletion_marker: \"anat/*acq-defaced*_T1w.nii.gz\" # defacing: defaced T1w present\ncompletion_marker: \"scripts/recon-all.done\"         # freesurfer: exact file (no glob chars)\n</code></pre> <p>Glob vs. literal path</p> <p>If the marker contains <code>*</code>, <code>?</code>, or <code>[</code>, it is treated as a glob pattern. Otherwise it is treated as a literal relative path inside the output directory.</p>"},{"location":"configuration/completion-markers/#list-of-glob-patterns-all-must-match","title":"List of glob patterns \u2014 ALL must match","text":"<pre><code>completion_marker:\n  - \"anat/*_T1w.nii.gz\"\n  - \"dwi/*dir-AP*_dwi.nii.gz\"\n  - \"dwi/*dir-AP*_dwi.bvec\"\n  - \"dwi/*dir-AP*_dwi.bval\"\n</code></pre> <p>Every pattern in the list must match at least one file. If any pattern has no match, the procedure is considered incomplete.</p> <p>Used by: <code>bids</code> (checks all expected modalities), <code>qsiprep</code> (checks all output DWI files)</p>"},{"location":"configuration/completion-markers/#output-path-context","title":"Output path context","text":"<p>The marker is evaluated relative to the procedure's output directory for the given subject/session:</p> Scope Output path <code>session</code> <code>&lt;proc_root&gt;/sub-XXXX/ses-YYYY/</code> <code>subject</code> <code>&lt;proc_root&gt;/sub-XXXX/</code> <p>Where <code>proc_root</code> is: - <code>bids_root</code> when <code>output_dir</code> is empty (bids, bids_post, defacing) - <code>derivatives_root/&lt;output_dir&gt;</code> otherwise</p>"},{"location":"configuration/completion-markers/#specialized-checks","title":"Specialized checks","text":"<p>For <code>freesurfer</code>, <code>qsiprep</code>, and <code>qsirecon</code> the completion marker is augmented by specialized logic that also checks session count consistency:</p> <ul> <li>freesurfer: <code>scripts/recon-all.done</code> must exist, and the number of <code>-i</code> inputs in <code>recon-all.done</code>'s <code>CMDARGS</code> line must equal the number of T1w files currently available in the BIDS dataset for that subject</li> <li>qsiprep: at least one <code>ses-*</code> subdirectory must exist in the output, and the count must equal the number of BIDS sessions with DWI data for that subject</li> <li>qsirecon: similar to qsiprep but compares against the number of QSIPrep sessions</li> </ul> <p>These checks prevent a procedure from appearing \"complete\" when new sessions have been added after it was originally run.</p>"},{"location":"configuration/completion-markers/#choosing-the-right-marker","title":"Choosing the right marker","text":"Situation Recommended marker Tool writes a known completion flag file <code>\"scripts/recon-all.done\"</code> or similar Tool writes output NIfTI files in predictable locations <code>\"**/*.nii.gz\"</code> or a specific glob Tool writes many files, all-or-nothing List of critical output globs Tool output is non-empty directory (coarse check) <code>null</code>"},{"location":"configuration/slurm/","title":"Slurm Settings","text":""},{"location":"configuration/slurm/#config-file-settings","title":"Config file settings","text":"<pre><code>slurm_partition: debug       # omit --partition if empty or omitted\nslurm_account:   snbb        # --account=snbb\nslurm_mem:       32G         # --mem=32G  (omitted from sbatch if null)\nslurm_cpus_per_task: 8       # --cpus-per-task=8  (omitted if null)\nslurm_log_dir:   /data/snbb/logs/slurm\n</code></pre>"},{"location":"configuration/slurm/#generated-sbatch-command","title":"Generated sbatch command","text":"<p>For a <code>qsiprep</code> job with the above config:</p> <pre><code>sbatch \\\n  --partition=debug \\\n  --account=snbb \\\n  --job-name=qsiprep_sub-0001 \\\n  --mem=32G \\\n  --cpus-per-task=8 \\\n  --output=/data/snbb/logs/slurm/qsiprep/qsiprep_sub-0001_%j.out \\\n  --error=/data/snbb/logs/slurm/qsiprep/qsiprep_sub-0001_%j.err \\\n  snbb_run_qsiprep.sh sub-0001\n</code></pre> <p>For a session-scoped procedure like <code>bids</code>:</p> <pre><code>sbatch \\\n  --partition=debug \\\n  --account=snbb \\\n  --job-name=bids_sub-0001_ses-202411010600 \\\n  --output=/data/snbb/logs/slurm/bids/bids_sub-0001_ses-202411010600_%j.out \\\n  --error=/data/snbb/logs/slurm/bids/bids_sub-0001_ses-202411010600_%j.err \\\n  snbb_run_bids.sh sub-0001 ses-202411010600 /data/snbb/dicom/sub-0001/ses-202411010600\n</code></pre> <p>Note that session-scoped scripts also receive the <code>dicom_path</code> as a third argument.</p>"},{"location":"configuration/slurm/#job-naming","title":"Job naming","text":"<p>Job names follow the pattern:</p> Scope Job name <code>subject</code> <code>&lt;procedure&gt;_&lt;subject&gt;</code> <code>session</code> <code>&lt;procedure&gt;_&lt;subject&gt;_&lt;session&gt;</code>"},{"location":"configuration/slurm/#log-file-naming","title":"Log file naming","text":"<p>When <code>slurm_log_dir</code> is set, logs are placed in per-procedure subdirectories:</p> <pre><code>slurm_log_dir/\n\u251c\u2500\u2500 bids/\n\u2502   \u251c\u2500\u2500 bids_sub-0001_ses-202411010600_12345.out\n\u2502   \u2514\u2500\u2500 bids_sub-0001_ses-202411010600_12345.err\n\u251c\u2500\u2500 qsiprep/\n\u2502   \u251c\u2500\u2500 qsiprep_sub-0001_12346.out\n\u2502   \u2514\u2500\u2500 qsiprep_sub-0001_12346.err\n\u2514\u2500\u2500 freesurfer/\n    \u251c\u2500\u2500 freesurfer_sub-0001_12347.out\n    \u2514\u2500\u2500 freesurfer_sub-0001_12347.err\n</code></pre> <p>The <code>%j</code> placeholder in <code>--output</code>/<code>--error</code> is replaced by Slurm with the actual job ID.</p>"},{"location":"configuration/slurm/#clusters-without-partitions","title":"Clusters without partitions","text":"<p>Some clusters do not use Slurm partitions. Leave <code>slurm_partition</code> empty or omit it:</p> <pre><code>slurm_partition: \"\"    # --partition flag is NOT added to sbatch\nslurm_account:   snbb\n</code></pre>"},{"location":"configuration/slurm/#per-invocation-overrides","title":"Per-invocation overrides","text":"<p>You can override Slurm settings without editing <code>config.yaml</code>:</p> <pre><code>snbb-scheduler --config config.yaml --slurm-mem 64G run\nsnbb-scheduler --config config.yaml --slurm-cpus 16 run\nsnbb-scheduler --config config.yaml --slurm-log-dir /tmp/logs run\n</code></pre> <p>These take precedence over the config file values.</p>"},{"location":"configuration/slurm/#environment-variables-in-scripts","title":"Environment variables in scripts","text":"<p>The shell scripts accept their Slurm resource requests from the environment or from embedded <code>#SBATCH</code> directives in the script itself. If you need per-procedure resource customization (e.g., freesurfer gets more CPUs than bids), set <code>#SBATCH</code> lines inside each script rather than using the global <code>slurm_mem</code> / <code>slurm_cpus_per_task</code> config. See Shell Scripts reference for details.</p>"},{"location":"guides/adding-procedure/","title":"Adding a Procedure","text":"<p>Adding a new pipeline step to snbb-scheduler requires no code changes. You just declare the procedure.</p>"},{"location":"guides/adding-procedure/#option-a-yaml-only-recommended","title":"Option A \u2014 YAML only (recommended)","text":"<p>Add the procedure to the <code>procedures</code> list in your <code>config.yaml</code>. When you provide a <code>procedures</code> key, it replaces the built-in defaults, so include all the procedures you want to run.</p>"},{"location":"guides/adding-procedure/#example-add-qsirecon-with-custom-output-dir","title":"Example: add qsirecon with custom output dir","text":"<pre><code>procedures:\n  - name: bids\n    output_dir: \"\"\n    script: snbb_run_bids.sh\n    scope: session\n    depends_on: []\n    completion_marker:\n      - \"anat/*_T1w.nii.gz\"\n      - \"dwi/*dir-AP*_dwi.nii.gz\"\n      - \"dwi/*dir-AP*_dwi.bvec\"\n      - \"dwi/*dir-AP*_dwi.bval\"\n      - \"dwi/*dir-PA*_dwi.nii.gz\"\n      - \"fmap/*acq-func_dir-AP*epi.nii.gz\"\n      - \"fmap/*acq-func_dir-PA*epi.nii.gz\"\n      - \"func/*task-rest_bold.nii.gz\"\n\n  - name: bids_post\n    output_dir: \"\"\n    script: snbb_run_bids_post.sh\n    scope: session\n    depends_on: [bids]\n    completion_marker: \"fmap/*acq-dwi*_epi.nii.gz\"\n\n  - name: defacing\n    output_dir: \"\"\n    script: snbb_run_defacing.sh\n    scope: session\n    depends_on: [bids_post]\n    completion_marker: \"anat/*acq-defaced*_T1w.nii.gz\"\n\n  - name: qsiprep\n    output_dir: qsiprep\n    script: snbb_run_qsiprep.sh\n    scope: subject\n    depends_on: [bids_post]\n    completion_marker:\n      - \"ses-*/dwi/*dir-AP*_dwi_preproc.nii.gz\"\n      - \"ses-*/dwi/*dir-AP*_dwi_preproc.bvec\"\n      - \"ses-*/dwi/*dir-AP*_dwi_preproc.bval\"\n      - \"ses-*/dwi/*dir-AP*desc-image_qc.tsv\"\n\n  - name: freesurfer\n    output_dir: freesurfer\n    script: snbb_run_freesurfer.sh\n    scope: subject\n    depends_on: [bids_post]\n    completion_marker: \"scripts/recon-all.done\"\n\n  - name: qsirecon\n    output_dir: qsirecon-MRtrix3_act-HSVS\n    script: snbb_run_qsirecon.sh\n    scope: subject\n    depends_on: [qsiprep, freesurfer]\n    completion_marker: null\n\n  # \u2500\u2500\u2500 New procedure \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  - name: fmriprep\n    output_dir: fmriprep\n    script: snbb_run_fmriprep.sh\n    scope: session\n    depends_on: [bids]\n    completion_marker: \"**/*.html\"   # fmriprep writes an HTML report when done\n</code></pre> <p>On the next <code>run</code>, the scheduler will: - include <code>fmriprep_path</code> and <code>fmriprep_exists</code> columns in the sessions DataFrame - generate a rule that triggers <code>fmriprep</code> when <code>bids</code> is complete and <code>fmriprep</code> is not - pass <code>subject</code> and <code>session</code> as arguments to <code>snbb_run_fmriprep.sh</code></p>"},{"location":"guides/adding-procedure/#option-b-python-api-for-programmatic-setups","title":"Option B \u2014 Python API (for programmatic setups)","text":"<p>Use this when you need to build configs dynamically or in code:</p> <pre><code>from snbb_scheduler.config import DEFAULT_PROCEDURES, Procedure, SchedulerConfig\n\nfmriprep = Procedure(\n    name=\"fmriprep\",\n    output_dir=\"fmriprep\",\n    script=\"snbb_run_fmriprep.sh\",\n    scope=\"session\",\n    depends_on=[\"bids\"],\n    completion_marker=\"**/*.html\",\n)\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\ncfg.procedures.append(fmriprep)\n</code></pre> <p>Or build the full config programmatically:</p> <pre><code>cfg = SchedulerConfig(\n    dicom_root=\"/data/snbb/dicom\",\n    bids_root=\"/data/snbb/bids\",\n    derivatives_root=\"/data/snbb/derivatives\",\n    state_file=\"/data/snbb/.scheduler_state.parquet\",\n    procedures=list(DEFAULT_PROCEDURES) + [fmriprep],\n)\n</code></pre>"},{"location":"guides/adding-procedure/#writing-the-shell-script","title":"Writing the shell script","text":"<p>Each procedure script must:</p> <ol> <li>Accept <code>subject</code> as <code>$1</code> (all procedures)</li> <li>Accept <code>session</code> as <code>$2</code> and <code>dicom_path</code> as <code>$3</code> (session-scoped procedures only)</li> <li>Exit with code 0 on success, non-zero on failure</li> </ol>"},{"location":"guides/adding-procedure/#minimal-session-scoped-script-template","title":"Minimal session-scoped script template","text":"<pre><code>#!/usr/bin/env bash\nset -euo pipefail\n\nSUBJECT=$1\nSESSION=$2\nDICOM_PATH=${3:-}   # optional; may be empty for file-based session discovery\n\n# Your processing command here\napptainer run \\\n  --bind /data:/data \\\n  /containers/mytool.sif \\\n  --subject \"$SUBJECT\" \\\n  --session \"$SESSION\"\n</code></pre>"},{"location":"guides/adding-procedure/#minimal-subject-scoped-script-template","title":"Minimal subject-scoped script template","text":"<pre><code>#!/usr/bin/env bash\nset -euo pipefail\n\nSUBJECT=$1\n\n# Your processing command here\napptainer run \\\n  --bind /data:/data \\\n  /containers/mytool.sif \\\n  --subject \"$SUBJECT\"\n</code></pre>"},{"location":"guides/adding-procedure/#environment-variables-available","title":"Environment variables available","text":"<p>Scripts run as Slurm batch jobs. They can read any environment variables set in the Slurm environment or exported by the submitting shell. See Shell Scripts reference for the full list of variables used by the built-in scripts.</p>"},{"location":"guides/adding-procedure/#checking-your-new-procedure","title":"Checking your new procedure","text":"<p>After adding the procedure, verify:</p> <pre><code># Check it appears in the manifest\nsnbb-scheduler --config config.yaml manifest\n\n# Dry run to see the sbatch command\nsnbb-scheduler --config config.yaml run --dry-run\n</code></pre> <p>The new procedure's tasks should appear with the expected <code>subject</code>, <code>session</code>, and <code>priority</code>.</p>"},{"location":"guides/cron-setup/","title":"Cron / Systemd Setup","text":"<p>Run the scheduler automatically every day so new sessions are processed without manual intervention.</p>"},{"location":"guides/cron-setup/#cron","title":"cron","text":""},{"location":"guides/cron-setup/#minimal-cron-entry","title":"Minimal cron entry","text":"<pre><code># /etc/cron.d/snbb-scheduler\n# Run every day at 6:00 AM as the snbb service user\n0 6 * * * snbb-user snbb-scheduler --config /etc/snbb/config.yaml run &gt;&gt; /var/log/snbb_scheduler.log 2&gt;&amp;1\n</code></pre>"},{"location":"guides/cron-setup/#with-explicit-monitor-pass","title":"With explicit monitor pass","text":"<pre><code># /etc/cron.d/snbb-scheduler\n# 5:55 AM \u2014 update job statuses from sacct\n55 5 * * * snbb-user snbb-scheduler --config /etc/snbb/config.yaml monitor &gt;&gt; /var/log/snbb_scheduler.log 2&gt;&amp;1\n\n# 6:00 AM \u2014 submit new jobs\n0 6 * * * snbb-user snbb-scheduler --config /etc/snbb/config.yaml run &gt;&gt; /var/log/snbb_scheduler.log 2&gt;&amp;1\n</code></pre> <p>Note</p> <p><code>snbb-scheduler run</code> already runs <code>monitor</code> internally before submission. The explicit pre-run monitor is only needed if you want to separate the sacct polling from the submission step, e.g. to log them separately.</p>"},{"location":"guides/cron-setup/#log-rotation","title":"Log rotation","text":"<p>Add a logrotate config to prevent the log file from growing unbounded:</p> <pre><code># /etc/logrotate.d/snbb-scheduler\n/var/log/snbb_scheduler.log {\n    daily\n    rotate 30\n    compress\n    missingok\n    notifempty\n    dateext\n}\n</code></pre>"},{"location":"guides/cron-setup/#systemd-timer","title":"systemd timer","text":"<p>A systemd timer is more flexible than cron: it handles missed runs, logs to the journal, and supports dependencies.</p>"},{"location":"guides/cron-setup/#service-unit","title":"Service unit","text":"<pre><code># /etc/systemd/system/snbb-scheduler.service\n[Unit]\nDescription=SNBB Scheduler \u2014 daily neuroimaging pipeline submission\nAfter=network.target\n\n[Service]\nType=oneshot\nUser=snbb-user\nExecStart=/usr/local/bin/snbb-scheduler --config /etc/snbb/config.yaml run\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=snbb-scheduler\n</code></pre>"},{"location":"guides/cron-setup/#timer-unit","title":"Timer unit","text":"<pre><code># /etc/systemd/system/snbb-scheduler.timer\n[Unit]\nDescription=Run SNBB Scheduler daily at 06:00\n\n[Timer]\nOnCalendar=*-*-* 06:00:00\nPersistent=true      # run missed timer if system was down\n\n[Install]\nWantedBy=timers.target\n</code></pre>"},{"location":"guides/cron-setup/#enable-and-start","title":"Enable and start","text":"<pre><code>systemctl daemon-reload\nsystemctl enable --now snbb-scheduler.timer\n\n# Check status\nsystemctl status snbb-scheduler.timer\nsystemctl list-timers snbb-scheduler.timer\n\n# View logs\njournalctl -u snbb-scheduler.service -f\n</code></pre>"},{"location":"guides/cron-setup/#combined-run-monitor","title":"Combined run + monitor","text":"<p>To run monitor at 5:55 and submit at 6:00 using systemd:</p> <pre><code># /etc/systemd/system/snbb-monitor.service\n[Unit]\nDescription=SNBB Scheduler \u2014 job status update\n\n[Service]\nType=oneshot\nUser=snbb-user\nExecStart=/usr/local/bin/snbb-scheduler --config /etc/snbb/config.yaml monitor\n</code></pre> <pre><code># /etc/systemd/system/snbb-monitor.timer\n[Unit]\nDescription=Run SNBB monitor 5 minutes before submission\n\n[Timer]\nOnCalendar=*-*-* 05:55:00\nPersistent=true\n\n[Install]\nWantedBy=timers.target\n</code></pre>"},{"location":"guides/cron-setup/#recommendations","title":"Recommendations","text":"<ul> <li>Set <code>slurm_log_dir</code> in config so each Slurm job writes its stdout/stderr to a file you can inspect later</li> <li>Set <code>log_file</code> in config to persist the audit log alongside the state file</li> <li>Set up log rotation for both the cron/systemd log and the audit log</li> <li>Check <code>snbb-scheduler status</code> regularly to catch failed jobs before they accumulate</li> </ul>"},{"location":"guides/debugging/","title":"Debugging","text":"<p>Common problems and how to diagnose them.</p>"},{"location":"guides/debugging/#no-tasks-appear-in-the-manifest","title":"No tasks appear in the manifest","text":"<p>Symptom: <code>snbb-scheduler manifest</code> outputs <code>No tasks pending.</code></p> <p>Diagnosis:</p> <ol> <li> <p>Check if sessions are discovered:    <pre><code>python3 -c \"\nfrom snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.sessions import discover_sessions\ncfg = SchedulerConfig.from_yaml('/etc/snbb/config.yaml')\nsessions = discover_sessions(cfg)\nprint(f'Found {len(sessions)} sessions')\nprint(sessions[['subject', 'session', 'dicom_exists']].to_string())\n\"\n</code></pre></p> </li> <li> <p>Check if dicom_root exists and has the right structure:    <pre><code>dicom_root/\n\u251c\u2500\u2500 sub-0001/\n\u2502   \u2514\u2500\u2500 ses-202407110849/\n\u2502       \u2514\u2500\u2500 *.dcm\n</code></pre></p> </li> <li> <p>Check if all procedures are already complete:    <pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.sessions import discover_sessions\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\nsessions = discover_sessions(cfg)\n# Check bids_exists for all sessions\nprint(sessions[[\"subject\", \"session\", \"bids_exists\", \"qsiprep_exists\"]])\n</code></pre></p> </li> </ol>"},{"location":"guides/debugging/#jobs-stuck-as-pending","title":"Jobs stuck as <code>pending</code>","text":"<p>Symptom: <code>status</code> shows jobs as <code>pending</code> long after submission.</p> <p>Cause: sacct hasn't been polled, or the job is no longer in sacct's retention window.</p> <p>Fix:</p> <pre><code># Poll sacct and reconcile filesystem\nsnbb-scheduler --config config.yaml monitor\n\n# If the output exists on disk, it will be marked complete automatically.\n# If sacct reports the job as failed, status will update to failed.\n</code></pre> <p>If the job is not in sacct and the output doesn't exist, the entry remains <code>pending</code>. Clear it manually:</p> <pre><code>import pandas as pd\nstate = pd.read_parquet(\"/data/snbb/.scheduler_state.parquet\")\n# Remove the stuck entry\nstate = state[~((state[\"subject\"]==\"sub-0001\") &amp; (state[\"procedure\"]==\"bids\"))].reset_index(drop=True)\nstate.to_parquet(\"/data/snbb/.scheduler_state.parquet\", index=False)\n</code></pre>"},{"location":"guides/debugging/#sbatch-fails-with-permission-error","title":"<code>sbatch</code> fails with permission error","text":"<p>Symptom: <code>subprocess.CalledProcessError</code> on <code>sbatch</code>.</p> <p>Diagnosis: - Verify the script is on <code>$PATH</code> or provide a full path - Verify the script is executable: <code>chmod +x snbb_run_bids.sh</code> - Check Slurm account: <code>sacctmgr show user $USER</code> - Check partition exists: <code>sinfo -p &lt;partition&gt;</code></p>"},{"location":"guides/debugging/#config-errors","title":"Config errors","text":""},{"location":"guides/debugging/#filenotfounderror","title":"<code>FileNotFoundError</code>","text":"<pre><code>FileNotFoundError: [Errno 2] No such file or directory: '/etc/snbb/config.yaml'\n</code></pre> <p>Pass the correct path with <code>--config</code>.</p>"},{"location":"guides/debugging/#valueerror-invalid-yaml","title":"<code>ValueError: Invalid YAML</code>","text":"<pre><code>ValueError: Invalid YAML in config.yaml: ...\n</code></pre> <p>Validate your YAML syntax: <pre><code>python3 -c \"import yaml; yaml.safe_load(open('config.yaml'))\"\n</code></pre></p>"},{"location":"guides/debugging/#valueerror-procedure-x-depends-on-y-which-is-not-in-the-procedures-list","title":"<code>ValueError: Procedure X depends on Y which is not in the procedures list</code>","text":"<p>You defined a procedure in <code>depends_on</code> that doesn't exist. Check procedure names in your <code>procedures</code> list.</p>"},{"location":"guides/debugging/#duplicate-jobs-submitted","title":"Duplicate jobs submitted","text":"<p>Symptom: Multiple jobs with the same <code>subject</code>, <code>session</code>, <code>procedure</code> in the state file.</p> <p>Cause: <code>--force</code> was used, or the state file was manually edited inconsistently.</p> <p>Fix: The in-flight filter prevents this in normal operation. After using <code>--force</code>, the state file may have duplicate entries \u2014 that's expected. Use <code>monitor</code> and then check <code>status</code> to see their final states.</p>"},{"location":"guides/debugging/#freesurfer-never-marked-complete","title":"FreeSurfer never marked complete","text":"<p>Symptom: <code>freesurfer_exists</code> is <code>True</code> but freesurfer keeps appearing in the manifest.</p> <p>Cause: The specialized <code>freesurfer</code> check also verifies that the number of T1w inputs in <code>recon-all.done</code> matches the currently available T1w files. If a new session was added, the check fails.</p> <p>Fix: Re-run freesurfer to incorporate the new session: <pre><code>snbb-scheduler --config config.yaml run --force --procedure freesurfer --dry-run\nsnbb-scheduler --config config.yaml run --force --procedure freesurfer\n</code></pre></p>"},{"location":"guides/debugging/#sacct-not-available","title":"sacct not available","text":"<p>Symptom: <code>WARNING snbb_scheduler.monitor: sacct not found; skipping job status update.</code></p> <p>Cause: The <code>sacct</code> command is not on <code>$PATH</code> (common on login nodes without Slurm in the environment).</p> <p>Fix: Ensure Slurm tools are loaded: <pre><code>module load slurm\n</code></pre> Or set <code>$PATH</code> to include the Slurm binaries. Filesystem reconciliation still works without sacct.</p>"},{"location":"guides/debugging/#state-file-corruption","title":"State file corruption","text":"<p>Symptom: <code>pd.read_parquet</code> raises an error or returns unexpected data.</p> <p>Fix: Back up the corrupt file and create a fresh one by deleting it. The scheduler will create a new empty state file on the next run. You will lose history of previously submitted jobs, but the filesystem is the source of truth \u2014 <code>reconcile_with_filesystem</code> will re-discover completed outputs.</p> <pre><code>cp /data/snbb/.scheduler_state.parquet /data/snbb/.scheduler_state.parquet.bak\nrm /data/snbb/.scheduler_state.parquet\n</code></pre>"},{"location":"guides/forcing-rerun/","title":"Forcing a Rerun","text":"<p>Sometimes you need to re-run a procedure that the scheduler considers already complete, or override the in-flight filter. There are three levels of force, from least to most invasive.</p>"},{"location":"guides/forcing-rerun/#level-1-force-a-single-procedure-recommended","title":"Level 1 \u2014 Force a single procedure (recommended)","text":"<p>Use <code>--force --procedure</code> to re-queue one procedure across all subjects/sessions, bypassing both the completion check and the in-flight filter:</p> <pre><code>snbb-scheduler --config config.yaml run --force --procedure qsiprep\n</code></pre> <p>This submits a new <code>qsiprep</code> job for every subject, even those already marked <code>complete</code> or <code>running</code>. Use <code>--dry-run</code> first to preview:</p> <pre><code>snbb-scheduler --config config.yaml run --dry-run --force --procedure qsiprep\n</code></pre>"},{"location":"guides/forcing-rerun/#level-2-force-all-procedures","title":"Level 2 \u2014 Force all procedures","text":"<p>Use <code>--force</code> alone to re-queue all procedures:</p> <pre><code>snbb-scheduler --config config.yaml run --force\n</code></pre> <p>Warning</p> <p>This submits jobs for every session and every procedure regardless of status. Only use this after a major environment change (e.g. upgrading a container, wiping derivatives).</p>"},{"location":"guides/forcing-rerun/#level-3-manual-state-surgery","title":"Level 3 \u2014 Manual state surgery","text":"<p>For precise control \u2014 e.g., force re-run of one specific subject for one procedure \u2014 edit the state file directly with pandas:</p> <pre><code>import pandas as pd\n\nstate_path = \"/data/snbb/.scheduler_state.parquet\"\nstate = pd.read_parquet(state_path)\n\n# Remove sub-0003's freesurfer entry so it gets re-submitted\nmask = (state[\"subject\"] == \"sub-0003\") &amp; (state[\"procedure\"] == \"freesurfer\")\nstate = state[~mask].reset_index(drop=True)\n\nstate.to_parquet(state_path, index=False)\n</code></pre> <p>After saving, run the scheduler normally:</p> <pre><code>snbb-scheduler --config config.yaml run\n</code></pre>"},{"location":"guides/forcing-rerun/#common-scenarios","title":"Common scenarios","text":""},{"location":"guides/forcing-rerun/#qsiprep-ran-with-wrong-parameters-re-run-for-all-subjects","title":"\"qsiprep ran with wrong parameters \u2014 re-run for all subjects\"","text":"<pre><code># 1. Preview\nsnbb-scheduler --config config.yaml run --dry-run --force --procedure qsiprep\n\n# 2. Submit\nsnbb-scheduler --config config.yaml run --force --procedure qsiprep\n</code></pre>"},{"location":"guides/forcing-rerun/#new-t1w-session-added-freesurfer-needs-to-re-run-for-sub-0001","title":"\"New T1w session added \u2014 freesurfer needs to re-run for sub-0001\"","text":"<p>The freesurfer completion check detects the new session automatically (it compares the number of T1w inputs used vs. available). The next unforced <code>run</code> will pick it up.</p> <p>But if you want to force it immediately:</p> <pre><code>import pandas as pd\n\nstate_path = \"/data/snbb/.scheduler_state.parquet\"\nstate = pd.read_parquet(state_path)\nmask = (state[\"subject\"] == \"sub-0001\") &amp; (state[\"procedure\"] == \"freesurfer\")\nstate = state[~mask].reset_index(drop=True)\nstate.to_parquet(state_path, index=False)\n</code></pre>"},{"location":"guides/forcing-rerun/#all-jobs-vanished-from-slurm-state-file-still-shows-pendingrunning","title":"\"All jobs vanished from Slurm \u2014 state file still shows pending/running\"","text":"<p>Run <code>monitor</code> first \u2014 it will use filesystem reconciliation to mark complete jobs:</p> <pre><code>snbb-scheduler --config config.yaml monitor\n</code></pre> <p>For any that are still stuck as <code>pending</code> after monitoring, clear them:</p> <pre><code>import pandas as pd\n\nstate_path = \"/data/snbb/.scheduler_state.parquet\"\nstate = pd.read_parquet(state_path)\n\n# Clear all stuck pending/running (will be re-submitted on next run)\nstuck = state[\"status\"].isin([\"pending\", \"running\"])\nstate = state[~stuck].reset_index(drop=True)\nstate.to_parquet(state_path, index=False)\n</code></pre>"},{"location":"guides/forcing-rerun/#notes","title":"Notes","text":"<ul> <li><code>--force</code> does not delete existing output. If you want a clean re-run, manually remove the output directory first.</li> <li>After forced submission, use <code>monitor</code> regularly to track the new jobs.</li> <li>The audit log records all <code>dry_run</code> events so you can review what was attempted.</li> </ul>"},{"location":"guides/getting-started/","title":"Getting Started","text":"<p>This guide walks you from a fresh install to a working pipeline in 5 steps.</p>"},{"location":"guides/getting-started/#step-1-install","title":"Step 1 \u2014 Install","text":"<pre><code>git clone https://github.com/GalKepler/snbb_scheduler.git\ncd snbb_scheduler\npip install -e \".[dev]\"\n</code></pre> <p>Verify:</p> <pre><code>snbb-scheduler --help\n</code></pre>"},{"location":"guides/getting-started/#step-2-create-a-config-file","title":"Step 2 \u2014 Create a config file","text":"<p>Create <code>/etc/snbb/config.yaml</code> (or any path you prefer):</p> <pre><code>dicom_root:       /data/snbb/dicom\nbids_root:        /data/snbb/bids\nderivatives_root: /data/snbb/derivatives\nstate_file:       /data/snbb/.scheduler_state.parquet\n\nslurm_partition: normal\nslurm_account:   snbb\nslurm_log_dir:   /data/snbb/logs/slurm\n</code></pre> <p>This uses the built-in default procedures (bids \u2192 bids_post \u2192 defacing, bids_post \u2192 qsiprep, bids_post \u2192 freesurfer, qsiprep + freesurfer \u2192 qsirecon).</p>"},{"location":"guides/getting-started/#expected-directory-layout","title":"Expected directory layout","text":"<pre><code>/data/snbb/dicom/\n\u251c\u2500\u2500 sub-0001/\n\u2502   \u2514\u2500\u2500 ses-202407110849/\n\u2502       \u2514\u2500\u2500 *.dcm\n\u251c\u2500\u2500 sub-0002/\n\u2502   \u2514\u2500\u2500 ses-202407110849/\n\u2502       \u2514\u2500\u2500 *.dcm\n</code></pre>"},{"location":"guides/getting-started/#step-3-dry-run","title":"Step 3 \u2014 Dry run","text":"<p>See what would be submitted without touching Slurm:</p> <pre><code>snbb-scheduler --config /etc/snbb/config.yaml run --dry-run\n</code></pre> <p>Expected output:</p> <pre><code>Discovering sessions\u2026\n  Found 2 session(s).\n  2 task(s) need processing.\n  2 task(s) after filtering in-flight jobs.\n[DRY RUN] Would submit: sbatch --partition=normal --account=snbb --job-name=bids_sub-0001_ses-202407110849 snbb_run_bids.sh sub-0001 ses-202407110849 /data/snbb/dicom/sub-0001/ses-202407110849\n[DRY RUN] Would submit: sbatch --partition=normal --account=snbb --job-name=bids_sub-0002_ses-202407110849 snbb_run_bids.sh sub-0002 ses-202407110849 /data/snbb/dicom/sub-0002/ses-202407110849\n[DRY RUN] Would submit 2 job(s).\n</code></pre> <p>If the output looks wrong, check your config paths and verify the DICOM directory structure.</p>"},{"location":"guides/getting-started/#step-4-submit-real-jobs","title":"Step 4 \u2014 Submit real jobs","text":"<pre><code>snbb-scheduler --config /etc/snbb/config.yaml run\n</code></pre> <p>The scheduler submits the jobs and saves their job IDs to the state file.</p>"},{"location":"guides/getting-started/#step-5-check-status","title":"Step 5 \u2014 Check status","text":"<pre><code>snbb-scheduler --config /etc/snbb/config.yaml status\n</code></pre> <pre><code>Summary:\n  procedure  status  count\n       bids  pending      2\n\n   subject                session  procedure  status           submitted_at  job_id\n  sub-0001  ses-202407110849       bids       pending  2024-11-01 06:00:00   10234\n  sub-0002  ses-202407110849       bids       pending  2024-11-01 06:00:00   10235\n</code></pre>"},{"location":"guides/getting-started/#after-jobs-complete","title":"After jobs complete","text":"<p>Once the <code>bids</code> jobs finish on Slurm, run <code>monitor</code> to update their status:</p> <pre><code>snbb-scheduler --config /etc/snbb/config.yaml monitor\n</code></pre> <p>Then run again to submit the next pipeline stage:</p> <pre><code>snbb-scheduler --config /etc/snbb/config.yaml run\n</code></pre> <p>The scheduler sees the <code>bids</code> output on disk and submits <code>bids_post</code> jobs for those sessions.</p>"},{"location":"guides/getting-started/#if-a-job-fails","title":"If a job fails","text":"<pre><code># See what failed\nsnbb-scheduler --config /etc/snbb/config.yaml status\n\n# Clear failed entries\nsnbb-scheduler --config /etc/snbb/config.yaml retry\n\n# Resubmit\nsnbb-scheduler --config /etc/snbb/config.yaml run\n</code></pre>"},{"location":"guides/getting-started/#setting-up-automation","title":"Setting up automation","text":"<p>Add a cron job to run the scheduler daily:</p> <pre><code># /etc/cron.d/snbb-scheduler\n0 6 * * * snbb-user snbb-scheduler --config /etc/snbb/config.yaml run &gt;&gt; /var/log/snbb_scheduler.log 2&gt;&amp;1\n</code></pre> <p>See Cron / Systemd Setup for a complete example with monitoring.</p>"},{"location":"guides/monitoring-jobs/","title":"Monitoring Jobs","text":"<p>The scheduler tracks job status through three complementary mechanisms.</p>"},{"location":"guides/monitoring-jobs/#1-sacct-polling-monitor-command","title":"1. sacct polling (<code>monitor</code> command)","text":"<p><code>snbb-scheduler monitor</code> queries <code>sacct</code> for the current Slurm state of every in-flight job and updates the state file:</p> <pre><code>snbb-scheduler --config config.yaml monitor\n</code></pre> <p>Output:</p> <pre><code>Updated 4 job status(es).\n    procedure    status  count\n         bids  complete     12\n     bids_post  complete      9\n     bids_post   running      3\n      qsiprep   running      2\n   freesurfer    failed       1\n</code></pre> <p>The monitor runs automatically at the start of <code>snbb-scheduler run</code> (unless <code>--skip-monitor</code> is passed), so you usually don't need to call it separately unless you want status updates without triggering a new submission pass.</p>"},{"location":"guides/monitoring-jobs/#2-filesystem-reconciliation","title":"2. Filesystem reconciliation","text":"<p><code>reconcile_with_filesystem</code> is called after every sacct poll. It scans the output directories for every job still marked <code>pending</code> or <code>running</code> and marks it <code>complete</code> if the completion check passes.</p> <p>This is especially useful when: - sacct no longer tracks a job (outside the retention window) - the cluster was rescheduled and job IDs changed - you manually ran a procedure outside the scheduler</p> <p>Filesystem reconciliation runs automatically as part of both <code>monitor</code> and <code>run</code>. You can also call it directly in Python:</p> <pre><code>from snbb_scheduler.config import SchedulerConfig\nfrom snbb_scheduler.manifest import load_state, reconcile_with_filesystem, save_state\n\ncfg = SchedulerConfig.from_yaml(\"/etc/snbb/config.yaml\")\nstate = load_state(cfg)\nupdated = reconcile_with_filesystem(state, cfg)\nif not updated.equals(state):\n    save_state(updated, cfg)\n    print(\"State updated.\")\n</code></pre>"},{"location":"guides/monitoring-jobs/#3-audit-log","title":"3. Audit log","text":"<p>Every status change is appended to a JSONL audit log. To watch it in real time:</p> <pre><code>tail -f /data/snbb/scheduler_audit.jsonl | python3 -c \"\nimport sys, json\nfor line in sys.stdin:\n    r = json.loads(line)\n    print(r['timestamp'], r['event'], r.get('procedure',''), r.get('subject',''), r.get('new_status',''))\n\"\n</code></pre> <p>To find all failed events:</p> <pre><code>grep '\"event\": \"status_change\"' /data/snbb/scheduler_audit.jsonl \\\n  | python3 -c \"\nimport sys, json\nfor line in sys.stdin:\n    r = json.loads(line)\n    if r.get('new_status') == 'failed':\n        print(r['timestamp'], r['procedure'], r['subject'], r.get('job_id',''))\n\"\n</code></pre> <p>See Audit Log reference for the full event schema.</p>"},{"location":"guides/monitoring-jobs/#recommended-monitoring-workflow","title":"Recommended monitoring workflow","text":""},{"location":"guides/monitoring-jobs/#for-daily-cron-use","title":"For daily cron use","text":"<p>Run monitor + run together. The <code>run</code> command handles both:</p> <pre><code>0 6 * * * snbb-user snbb-scheduler --config /etc/snbb/config.yaml run\n</code></pre> <p>This automatically polls sacct, reconciles the filesystem, and submits new jobs in one pass.</p>"},{"location":"guides/monitoring-jobs/#for-interactive-use","title":"For interactive use","text":"<pre><code># Update statuses\nsnbb-scheduler --config config.yaml monitor\n\n# Check results\nsnbb-scheduler --config config.yaml status\n\n# Retry failures\nsnbb-scheduler --config config.yaml retry\n\n# Submit new jobs\nsnbb-scheduler --config config.yaml run\n</code></pre>"},{"location":"guides/monitoring-jobs/#notes","title":"Notes","text":"<ul> <li><code>monitor</code> is safe to run at any time \u2014 it never submits jobs</li> <li>If <code>sacct</code> is not installed, monitor falls back to filesystem reconciliation only</li> <li>The scheduler does not set up Slurm job epilog scripts or callbacks \u2014 status is always polled, not pushed</li> </ul>"},{"location":"reference/audit-log/","title":"Audit Log","text":"<p>Every significant scheduler event is appended to a JSONL (newline-delimited JSON) file. One record per event, human-readable, easily processed with standard tools.</p>"},{"location":"reference/audit-log/#location","title":"Location","text":"<p>Defaults to <code>&lt;state_file_parent&gt;/scheduler_audit.jsonl</code>. Override in config:</p> <pre><code>log_file: /data/snbb/scheduler_audit.jsonl\n</code></pre>"},{"location":"reference/audit-log/#record-format","title":"Record format","text":"<p>Every record has these fields:</p> Field Type Description <code>timestamp</code> ISO 8601 datetime (UTC) When the event occurred <code>event</code> string Event type \u2014 see table below <code>subject</code> string BIDS subject label, or <code>\"\"</code> <code>session</code> string BIDS session label, or <code>\"\"</code> <code>procedure</code> string Procedure name, or <code>\"\"</code> <code>job_id</code> string Slurm job ID (when applicable) <code>old_status</code> string Previous status (for <code>status_change</code> events) <code>new_status</code> string New status (for <code>status_change</code> events) <code>detail</code> string Extra context (for <code>error</code> and <code>dry_run</code> events)"},{"location":"reference/audit-log/#event-types","title":"Event types","text":"Event Triggered by Key fields <code>submitted</code> Job submitted to Slurm <code>job_id</code> <code>status_change</code> sacct poll or filesystem reconciliation updates a status <code>job_id</code>, <code>old_status</code>, <code>new_status</code> <code>error</code> <code>sbatch</code> exits non-zero <code>detail</code> (error message) <code>dry_run</code> <code>run --dry-run</code> <code>detail</code> (full sbatch command) <code>retry_cleared</code> <code>retry</code> removes a failed entry <code>job_id</code>, <code>old_status</code>"},{"location":"reference/audit-log/#example-records","title":"Example records","text":"<pre><code>{\"timestamp\": \"2024-11-01T06:00:12.345678+00:00\", \"event\": \"submitted\", \"subject\": \"sub-0001\", \"session\": \"ses-202407110849\", \"procedure\": \"bids\", \"job_id\": \"10234\"}\n{\"timestamp\": \"2024-11-01T06:00:12.567890+00:00\", \"event\": \"submitted\", \"subject\": \"sub-0002\", \"session\": \"ses-202407110849\", \"procedure\": \"bids\", \"job_id\": \"10235\"}\n{\"timestamp\": \"2024-11-01T07:30:44.112233+00:00\", \"event\": \"status_change\", \"subject\": \"sub-0001\", \"session\": \"ses-202407110849\", \"procedure\": \"bids\", \"job_id\": \"10234\", \"old_status\": \"pending\", \"new_status\": \"complete\"}\n{\"timestamp\": \"2024-11-01T07:30:44.223344+00:00\", \"event\": \"status_change\", \"subject\": \"sub-0002\", \"session\": \"ses-202407110849\", \"procedure\": \"bids\", \"job_id\": \"10235\", \"old_status\": \"pending\", \"new_status\": \"failed\"}\n{\"timestamp\": \"2024-11-02T06:00:05.000000+00:00\", \"event\": \"retry_cleared\", \"subject\": \"sub-0002\", \"session\": \"ses-202407110849\", \"procedure\": \"bids\", \"job_id\": \"10235\", \"old_status\": \"failed\"}\n</code></pre>"},{"location":"reference/audit-log/#tailing-the-log","title":"Tailing the log","text":"<pre><code>tail -f /data/snbb/scheduler_audit.jsonl\n</code></pre> <p>Pretty-print with Python:</p> <pre><code>tail -f /data/snbb/scheduler_audit.jsonl | python3 -c \"\nimport sys, json\nfor line in sys.stdin:\n    r = json.loads(line)\n    print(r['timestamp'][:19], f'{r[\\\"event\\\"]:20s}', r.get('procedure',''), r.get('subject',''), r.get('new_status',''))\n\"\n</code></pre>"},{"location":"reference/audit-log/#querying-with-python","title":"Querying with Python","text":"<pre><code>import json\nimport pandas as pd\n\nrecords = []\nwith open(\"/data/snbb/scheduler_audit.jsonl\") as f:\n    for line in f:\n        records.append(json.loads(line))\n\ndf = pd.DataFrame(records)\ndf[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n\n# All failures\nfailures = df[df[\"new_status\"] == \"failed\"]\nprint(failures[[\"timestamp\", \"procedure\", \"subject\", \"job_id\"]])\n\n# Submissions per day\nsubmissions = df[df[\"event\"] == \"submitted\"].copy()\nsubmissions[\"date\"] = submissions[\"timestamp\"].dt.date\nprint(submissions.groupby(\"date\").size())\n</code></pre>"},{"location":"reference/audit-log/#querying-with-grep","title":"Querying with grep","text":"<pre><code># All failed status changes\ngrep '\"new_status\": \"failed\"' /data/snbb/scheduler_audit.jsonl\n\n# All events for sub-0003\ngrep '\"subject\": \"sub-0003\"' /data/snbb/scheduler_audit.jsonl\n\n# All retry events\ngrep '\"event\": \"retry_cleared\"' /data/snbb/scheduler_audit.jsonl\n</code></pre>"},{"location":"reference/scripts/","title":"Shell Scripts","text":"<p>Each procedure has a corresponding shell script in <code>scripts/</code>. These scripts are passed to <code>sbatch</code> and run on the cluster as Slurm batch jobs. All scripts accept positional arguments from the scheduler and read site-specific paths from environment variables.</p>"},{"location":"reference/scripts/#snbb_run_bidssh","title":"<code>snbb_run_bids.sh</code>","text":"<p>Converts DICOMs to BIDS format using heudiconv via Apptainer.</p> <p>Called as: <code>sbatch ... snbb_run_bids.sh sub-XXXX ses-YY /path/to/dicom</code></p> <p>Positional arguments:</p> <p>| <code>$1</code> | <code>SUBJECT</code> | BIDS subject label, e.g. <code>sub-0001</code> | | <code>$2</code> | <code>SESSION</code> | BIDS session label, e.g. <code>ses-202407110849</code> | | <code>$3</code> | <code>DICOM_PATH_ARG</code> | Optional explicit DICOM path; falls back to <code>SNBB_DICOM_SESSION_DIR</code> |</p> <p>Environment variables:</p> Variable Default Description <code>SNBB_DICOM_ROOT</code> <code>/data/snbb/dicom</code> Root of the DICOM tree <code>SNBB_DICOM_SESSION_DIR</code> <code>&lt;SNBB_DICOM_ROOT&gt;/&lt;SESSION_ID&gt;</code> Fallback per-session DICOM path <code>SNBB_BIDS_ROOT</code> (site-specific) Output BIDS dataset root <code>SNBB_HEURISTIC</code> (site-specific) Path to the heudiconv heuristic Python file <code>SNBB_HEUDICONV_SIF</code> (site-specific) Path to the heudiconv Apptainer image <code>SNBB_DEBUG_LOG</code> (site-specific) Path for the per-run debug log <p>Embedded Slurm resources: <pre><code>#SBATCH --time=4:00:00\n#SBATCH --mem=8G\n#SBATCH --cpus-per-task=4\n</code></pre></p>"},{"location":"reference/scripts/#snbb_run_bids_postsh","title":"<code>snbb_run_bids_post.sh</code>","text":"<p>Post-processing step: derives DWI fieldmap EPI sidecars from BIDS data.</p> <p>Called as: <code>sbatch ... snbb_run_bids_post.sh sub-XXXX ses-YY /path/to/dicom</code></p> <p>Calls <code>scripts/snbb_bids_post.py</code> to generate the derived <code>fmap/*acq-dwi*_epi</code> files required by QSIPrep.</p>"},{"location":"reference/scripts/#snbb_run_defacingsh","title":"<code>snbb_run_defacing.sh</code>","text":"<p>Defaces T1w images in-place within the BIDS dataset, writing defaced images as <code>anat/*acq-defaced*_T1w.nii.gz</code>.</p> <p>Called as: <code>sbatch ... snbb_run_defacing.sh sub-XXXX ses-YY /path/to/dicom</code></p>"},{"location":"reference/scripts/#snbb_run_qsiprepsh","title":"<code>snbb_run_qsiprep.sh</code>","text":"<p>DWI preprocessing via QSIPrep using Apptainer.</p> <p>Called as: <code>sbatch ... snbb_run_qsiprep.sh sub-XXXX</code> (subject-scoped: processes all sessions for the subject in one job)</p> <p>Environment variables:</p> Variable Default Description <code>SNBB_BIDS_ROOT</code> (site-specific) BIDS dataset root (read-only input) <code>SNBB_DERIVATIVES</code> (site-specific) Parent derivatives directory (qsiprep writes <code>qsiprep/</code> inside it) <code>SNBB_FS_LICENSE</code> (site-specific) FreeSurfer license file path <code>SNBB_WORK_DIR</code> (site-specific) QSIPrep working directory <code>SNBB_QSIPREP_SIF</code> (site-specific) Path to the QSIPrep Apptainer image <code>SNBB_ANATOMICAL_TEMPLATE</code> <code>MNI152NLin2009cAsym</code> Anatomical template space <code>SNBB_SUBJECT_ANAT_REF</code> <code>unbiased</code> Subject anatomical reference <code>SNBB_BIDS_FILTER_FILE</code> (optional) BIDS filter JSON file <code>SNBB_TEMPLATEFLOW_HOME</code> (site-specific) TemplateFlow cache directory <code>SNBB_LOCAL_TMP_ROOT</code> (empty) Enable local-scratch mode (see below) <p>Embedded Slurm resources: <pre><code>#SBATCH --time=12:00:00\n#SBATCH --mem=20G\n#SBATCH --cpus-per-task=8\n</code></pre></p>"},{"location":"reference/scripts/#local-scratch-mode","title":"Local-scratch mode","text":"<p>When <code>SNBB_LOCAL_TMP_ROOT</code> is set, the script stages BIDS input and QSIPrep output on the compute node's local disk (<code>/tmp</code> or similar), then rsyncs results back to <code>SNBB_DERIVATIVES</code> on success. This improves I/O performance on clusters with slow network filesystems. On failure, the local workdir is preserved for manual recovery.</p>"},{"location":"reference/scripts/#snbb_run_freesurfersh","title":"<code>snbb_run_freesurfer.sh</code>","text":"<p>Structural reconstruction via FreeSurfer <code>recon-all</code>, run inside an Apptainer container.</p> <p>Called as: <code>sbatch ... snbb_run_freesurfer.sh sub-XXXX</code> (subject-scoped)</p> <p>Uses <code>scripts/snbb_recon_all_helper.py</code> to collect all T1w (and T2w) NIfTI files across all BIDS sessions and build the <code>-i</code> argument list for <code>recon-all</code>.</p> <p>Environment variables:</p> Variable Default Description <code>SNBB_BIDS_ROOT</code> (site-specific) BIDS dataset root <code>SNBB_FS_OUTPUT</code> (site-specific) Final FreeSurfer output directory <code>SNBB_TMP_FS_OUTPUT</code> (site-specific) Intermediate writable FreeSurfer directory <code>SNBB_FS_LICENSE</code> (site-specific) FreeSurfer license file <code>SNBB_FREESURFER_SIF</code> (site-specific) FreeSurfer Apptainer image <code>SNBB_LOCAL_TMP_ROOT</code> (empty) Enable local-scratch mode <p>Embedded Slurm resources: <pre><code>#SBATCH --time=24:00:00\n#SBATCH --mem=20G\n#SBATCH --cpus-per-task=8\n</code></pre></p> <p>After <code>recon-all</code> completes, the script rsyncs results from the temporary directory to <code>SNBB_FS_OUTPUT</code> and removes the temp copy (only if <code>scripts/recon-all.done</code> is present).</p>"},{"location":"reference/scripts/#snbb_run_qsireconsh","title":"<code>snbb_run_qsirecon.sh</code>","text":"<p>Tractography and connectivity via QSIRecon using Apptainer.</p> <p>Called as: <code>sbatch ... snbb_run_qsirecon.sh sub-XXXX</code> (subject-scoped: processes all sessions for the subject)</p> <p>Environment variables:</p> Variable Default Description <code>SNBB_QSIPREP_DIR</code> (site-specific) QSIPrep output directory (input to QSIRecon) <code>SNBB_QSIRECON_OUTPUT_DIR</code> (site-specific) QSIRecon output directory <code>SNBB_FS_LICENSE</code> (site-specific) FreeSurfer license file <code>SNBB_FS_SUBJECTS_DIR</code> (site-specific) FreeSurfer subjects directory <code>SNBB_RECON_SPEC</code> (site-specific) QSIRecon reconstruction spec YAML <code>SNBB_WORK_DIR</code> (site-specific) QSIRecon working directory <code>SNBB_QSIRECON_SIF</code> (site-specific) QSIRecon Apptainer image <code>SNBB_RESPONSES_DIR</code> (optional) Pre-computed MRtrix3 response functions <code>SNBB_ATLASES_DIR</code> (optional) Atlas dataset directory <code>SNBB_ATLASES</code> (optional) Space-separated atlas names <code>SNBB_TEMPLATEFLOW_HOME</code> (site-specific) TemplateFlow cache directory <code>SNBB_LOCAL_TMP_ROOT</code> (empty) Enable local-scratch mode <p>Embedded Slurm resources: <pre><code>#SBATCH --time=12:00:00\n#SBATCH --mem=32G\n#SBATCH --cpus-per-task=8\n</code></pre></p>"},{"location":"reference/scripts/#snbb_recon_all_helperpy","title":"<code>snbb_recon_all_helper.py</code>","text":"<p>Python helper called by <code>snbb_run_freesurfer.sh</code>. Collects T1w and T2w NIfTI files for a subject (excluding defaced images, preferring <code>rec-norm</code> when available) and calls <code>recon-all</code> via the FreeSurfer Apptainer container.</p> <p>Arguments: <pre><code>--bids-dir    Path to BIDS root (or local copy)\n--output-dir  FreeSurfer SUBJECTS_DIR\n--subject     BIDS subject label (e.g. sub-0001)\n--threads     Number of parallel threads for recon-all\n--sif         Path to FreeSurfer Apptainer image\n--fs-license  Path to FreeSurfer license file\n</code></pre></p>"},{"location":"reference/scripts/#setting-environment-variables","title":"Setting environment variables","text":"<p>Environment variables can be set in three ways, in order of precedence:</p> <ol> <li>In the script itself (edit the default values at the top of each <code>.sh</code> file)</li> <li>In your Slurm environment (export before submitting, or set in <code>~/.bashrc</code>)</li> <li>Via <code>sbatch --export</code> (pass specific vars to the job)</li> </ol> <p>Example \u2014 set variables in your environment:</p> <pre><code>export SNBB_BIDS_ROOT=/data/site/bids\nexport SNBB_DERIVATIVES=/data/site/derivatives\nexport SNBB_FS_LICENSE=/opt/freesurfer/license.txt\nexport SNBB_QSIPREP_SIF=/containers/qsiprep-1.1.1.sif\nexport SNBB_FREESURFER_SIF=/containers/freesurfer-8.1.0.sif\nexport SNBB_QSIRECON_SIF=/containers/qsirecon-1.2.0.sif\nexport SNBB_TEMPLATEFLOW_HOME=/data/templateflow\n</code></pre>"},{"location":"reference/state-file/","title":"State File","text":"<p>The scheduler tracks every submitted job in a single Apache Parquet file. No external database is required.</p>"},{"location":"reference/state-file/#location","title":"Location","text":"<p>Set in <code>config.yaml</code>:</p> <pre><code>state_file: /data/snbb/.scheduler_state.parquet\n</code></pre> <p>The file is created automatically on first run if it does not exist.</p>"},{"location":"reference/state-file/#schema","title":"Schema","text":"Column dtype Description <code>subject</code> string BIDS subject label, e.g. <code>sub-0001</code> <code>session</code> string BIDS session label, e.g. <code>ses-202411010600</code>; empty string <code>\"\"</code> for subject-scoped procedures <code>procedure</code> string Procedure name, e.g. <code>bids</code>, <code>qsiprep</code>, <code>freesurfer</code> <code>status</code> string One of <code>pending</code>, <code>running</code>, <code>complete</code>, <code>failed</code> <code>submitted_at</code> datetime64[ns] UTC Timestamp when the job was submitted <code>job_id</code> string Slurm job ID returned by <code>sbatch</code>; <code>None</code> for dry-run entries"},{"location":"reference/state-file/#status-lifecycle","title":"Status lifecycle","text":"<pre><code>pending \u2192 running \u2192 complete\n               \u2198 failed\n</code></pre> Status Set when <code>pending</code> <code>sbatch</code> returns successfully <code>running</code> sacct reports the job is active (<code>RUNNING</code>) <code>complete</code> sacct reports <code>COMPLETED</code>, or filesystem reconciliation finds output <code>failed</code> sacct reports <code>FAILED</code>, <code>TIMEOUT</code>, <code>CANCELLED</code>, <code>OUT_OF_MEMORY</code>, or <code>NODE_FAIL</code>"},{"location":"reference/state-file/#reading-with-pandas","title":"Reading with pandas","text":"<pre><code>import pandas as pd\n\nstate = pd.read_parquet(\"/data/snbb/.scheduler_state.parquet\")\n\n# All failed jobs\nfailed = state[state[\"status\"] == \"failed\"]\nprint(failed[[\"subject\", \"session\", \"procedure\", \"job_id\"]])\n\n# Count by procedure and status\nprint(state.groupby([\"procedure\", \"status\"]).size().unstack(fill_value=0))\n\n# Jobs submitted today\nfrom datetime import date\ntoday = pd.Timestamp(date.today(), tz=\"UTC\")\ntoday_jobs = state[state[\"submitted_at\"] &gt;= today]\n\n# Running qsiprep jobs\nrunning_qsiprep = state[(state[\"procedure\"] == \"qsiprep\") &amp; (state[\"status\"] == \"running\")]\n</code></pre>"},{"location":"reference/state-file/#writing-with-pandas","title":"Writing with pandas","text":"<p>If you need to manually edit the state file, always read-modify-write to preserve schema:</p> <pre><code>import pandas as pd\n\npath = \"/data/snbb/.scheduler_state.parquet\"\nstate = pd.read_parquet(path)\n\n# Example: remove a stuck pending entry\nmask = (state[\"subject\"] == \"sub-0003\") &amp; (state[\"procedure\"] == \"freesurfer\")\nstate = state[~mask].reset_index(drop=True)\n\nstate.to_parquet(path, index=False)\n</code></pre>"},{"location":"reference/state-file/#backing-up-the-state-file","title":"Backing up the state file","text":"<pre><code>cp /data/snbb/.scheduler_state.parquet \\\n   /data/snbb/.scheduler_state.parquet.$(date +%Y%m%d)\n</code></pre> <p>Since the filesystem is the source of truth, losing the state file only means losing job history. Run <code>monitor</code> after restoring from backup to reconcile with the actual filesystem state.</p>"}]}